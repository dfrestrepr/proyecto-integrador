{"cells":[{"cell_type":"code","source":["import datetime as dt\ntime_ini = dt.datetime.now()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Tue Oct 15 19:20:05 2019\n\n#Proyecto Integrador\n\"\"\"\n### Paquetes necesarios para el funcionamiento de las funciones en este script\nimport logging\nimport numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\nfrom scipy.spatial import distance\nfrom sklearn.covariance import LedoitWolf\nfrom sklearn.tree import ExtraTreeClassifier\n#%%\n#from bokeh.layouts import layout\n#from bokeh.plotting import figure\n#from bokeh.palettes import Spectral6\n#from bokeh.io import output_file, save, curdoc\n#from bokeh.models import (ColumnDataSource, HoverTool, BoxZoomTool, \n#                          WheelZoomTool, ResetTool, PanTool,SingleIntervalTicker,\n#                          Slider, Button, Label, CategoricalColorMapper)\n#%%\nlogger = logging.getLogger(__name__)\n#%%\n\n### Esta funcion calcula la matriz de covarianza de Ledoit and Wolf, retorna\n### la matriz de covarianza despues de aplicar el metodo de Shrinkage, ademas\n### de retornar la media estimada. Esta funcion toma como parametros de entrada\n### el conjunto de datos\ndef LedoitWolf_covMatrix(X):\n    logger.info('Se realiza el calculo de la matriz de covarianza con Shrinkage')\n    cov = LedoitWolf().fit(X)\n    cov_matrix = cov.covariance_\n    mean_vector = cov.location_\n    \n    return cov_matrix, mean_vector\n\n### La funcion toma como entrada el conjunto de datos en el cual se desea\n### realizar la deteccion de outliers multivariante. El metodo utiliza la\n### distancia de Mahalanobis y la matriz de covarianza habitual. Se define\n### alpha como el percentil en el cual se realizara el corte de la matriz de \n### distancias para determinar que registros son considerados outliers. \ndef outlier_detection_mahal(X,alpha = 0.95, shrinkage = False):\n    logger.info('Comienza la deteccion de outliers')\n    if len(X)==0:\n        logger.info('No hay datos para realizar deteccion de outliers')\n        return None\n    try:\n        X = np.array(X)\n        X_arr = np.array(X)\n        X_mean = X_arr.mean(axis = 0)\n        \n        if shrinkage:\n            cov, _ = LedoitWolf_covMatrix(X)\n        else:\n            cov = np.array(pd.DataFrame(X).cov())\n        \n        \n        inv_cov = np.linalg.inv(cov)\n        \n        dist = []\n        i=0\n        while i<len(X):\n            distances = distance.mahalanobis(X_arr[i], X_mean, inv_cov)\n            dist.append(distances)\n            i +=1\n        \n        dist = np.array(dist)\n        cutoff = np.quantile(dist,alpha)\n        outliers = (dist>cutoff).astype(int)\n    except Exception as e:\n        logger.info('Error en la deteccion de outliers:{0}'.format(e))\n    \n    logger.info('Deteccion de outliers exitoso')\n    return outliers\n\n\n### Esta funcion toma como entrada un dataframe con el conjunto de datos, la\n### etiqueta de 1s y 0s, y realiza un stepwise en la regresion logistica para\n### conservar las variables mas relevantes para explicar la etiqueta. La\n### funcion devuelve una lista con las variables relevantes, y el modelo final\n### de la regresion logistica\ndef stepwise_logistic(X,Y,alpha =0.1):\n    \n    try:\n        n = len(X.columns)\n        for i in range(n):\n            model = sm.Logit(Y, X).fit()\n            pvalues = pd.DataFrame(model.pvalues,columns = ['pvalues']).reset_index()\n            if pvalues['pvalues'].max()<alpha:\n                break\n            to_drop = pvalues[pvalues['pvalues']==pvalues['pvalues'].max()]['index'].values[0]\n            X = X.drop(columns = to_drop)\n    \n        model = sm.Logit(Y, X).fit()\n        variables_relevantes = list(X.columns) \n    except Exception as e:\n        logger.info('Error en el stepwise logistic:{0}'.format(e))\n        model = None\n        variables_relevantes = []\n        \n    return variables_relevantes,model\n\n### Se construye la funcion de variables relevantes utilizando metodos de\n### arboles. Esta funcion entrena un arbol para el conjunto de datos y\n### retorna las variables mas relevantes para explicar la variable Y. Hay\n### que tener en cuenta que esta funcion toma como entrada DataFrames, donde\n### para la variable X, las columnas tienen los nombres de las variables.\ndef variables_relevantes_arbol(X,Y,alpha = None):\n    \n    if len(X)==0:\n        logger.info(\"No se ingreso informacion de variables\")\n        return []\n    \n    features = list(X.columns)\n    \n    if alpha == None:\n        alpha = 1.0/len(features)\n        logger.info('Se calcula el valor minimo de aceptacion de importancia: {0}'.format(alpha))\n    \n    try:    \n        model = ExtraTreeClassifier()\n        model.fit(X,Y)\n        \n        importance = model.feature_importances_ + 0.0001   ## Para evitar overflow\n        \n        relevant_features = []\n        for i in range(len(features)):\n            if importance[i]>alpha:\n                relevant_features.append(features[i])\n                \n    except Exception as e:\n        logger.info('Error con el metodo de arboles, no se determinaron variables relevantes: {0}'.format(e))\n        relevant_features = []\n        \n    return importance, relevant_features\n\n### Esta funcion toma como entrada un dataframe, el nombre de las variables no\n### numericas, el nombre de la columna identificadora de los registros (ID del\n### cliente, pais, etc) y realiza una deteccion de outliers utilizando la \n### distancia de Mahalanobis, adicional a esto, realiza la eliminacion de\n### variables redundantes en el conjunto de datos mirando la relacion lineal\n### de una variable contra todas las demas\ndef data_preprocessing(datos, alpha_outlier_detection =0.95, columns_not_numeric = {}, \n                       column_id = '', remove_vars = True, r_sqr_threshold = 0.9, shrinkage = False):\n    \n    ### Realiza la identificaciohn de outliers usando la distancia de \n    ### Mahalanobis\n    logger.info('Realiza deteccion de outlier en el preprocesamiento de los datos')\n    outliers = outlier_detection_mahal(datos.drop(columns = columns_not_numeric),\n                                       alpha = alpha_outlier_detection,\n                                       shrinkage = shrinkage)\n    \n    ### En caso que no exista una columna identificadora para eliminar IDs\n    ### outliers, se eliminan todos los registros que se encontraron como\n    ### outlier    \n    if column_id == '':\n        logger.info('Realiza la eliminacion de outliers por registros encontrados')\n        datos = datos[outliers==0].reset_index(drop = True)    \n        \n    else:\n        logger.info('Realiza la eliminacion de outliers por IDs detectados')              \n        ids_outliers = datos[outliers==1][column_id].unique()\n        datos = datos[~datos[column_id].isin(ids_outliers)].reset_index(drop = True) \n    \n    ### Esta seccion realiza eliminacion iterativa de variables de forma tal\n    ### que el R^2 de todas las variables sea menor a un umbral dado\n    if remove_vars:\n        logger.info('Se realiza el analisis del R^2 de todas las variables para eliminar variables redundantes')\n        to_drop = []\n        X_aux = datos.drop(columns = columns_not_numeric).copy()\n        while True:\n            var_names = list(X_aux.columns)\n            \n            inver = np.linalg.inv(X_aux.cov())\n    \n            ### Este es el R2 de cada variable con respecto a todas las demas, \n            ### por eso seria un R2 por cada variable\n            r_squared = 1 - 1/(np.diagonal(X_aux.cov())*np.diagonal(inver))\n    \n            if any(r_squared > r_sqr_threshold):\n                \n                var_m = np.argmax(r_squared)\n                X_aux = X_aux.drop(columns = var_names[var_m])\n                \n                to_drop.append(var_names[var_m])\n                logger.info('Se elimina la variable:var_names[var_m] con el umbral: {0}'.format(r_sqr_threshold))\n                \n            else:\n                break\n    \n    datos = datos.drop(columns = to_drop)\n    logger.info('Fin del preprocesamiento de los datos eliminando Outliers y variables redundantes')\n    return datos\n\n\n### Funcion de distancia p, tenga en cuenta que si p es cero, entonces se\n### asume que la distancia deseada es la de Mahalanobis\ndef distancia(a,b, p, cov = np.array([])):\n    \n    if p == 0:\n        inv_cov = np.linalg.inv(cov)\n        dist = distance.mahalanobis(a, b, inv_cov)\n    else:\n        dist = np.linalg.norm(a-b, p) \n    \n\n    return dist\n\n\n### Inicializa los centroides para el metodo de kmeans, inicializa de forma\n### aleatoria tantos centros como clusters\ndef init_centroids(X_data,k):\n    logger.info('Inicializacion de {0} centroides para el metodo de kmeans'.format(k))\n    centroids = []\n    numdata = len(X_data)\n    for i in range(k):\n        centroids.append(X_data[np.random.randint(0, numdata)])\n\n    return centroids\n\n### Metodo de kmeans\ndef kmeans_old(X_data,numiter,centroids,p_dista = 2,etiquetas = [], shrinkage = False):\n    logger.info('Inicializa el metodo de kmeans')\n    numdata = len(X_data)    \n    if len(etiquetas)==0:\n        logger.info('Se crean etiquetas ya que no fueron pasadas incialmente')\n         ### Etiquetas actuales de cada elemento para cada cluster\n        etiquetas = np.ones(numdata)*-1   ### Inicialmente, ningun elemento esta asignado\n    \n    ### Grados de pertenencia a cada cluster\n    grados_pertenencia = []\n    \n    ### Se realiza el calculo de la matriz de varianzas y covarianzas en caso\n    ### de utilizar la distancia de Mahalanobis, ademas si se desea, se utiliza\n    ### una version bien condicionada de la matriz utilizando el metodo de\n    ### Shrinkage\n    if shrinkage:      \n        covariance_matrix, _ = LedoitWolf_covMatrix(X_data)\n    else:      \n        covariance_matrix = np.cov(X_data,rowvar=False)\n        \n    ### Ahora empiezo las iteraciones\n    for it in range(numiter):\n        logger.info('Iteracion {0} de {1} para el metodo de kmeans'.format(it, numiter))\n        ### En cada iteracion, itero para todos los elementos\n        for element in range(numdata):\n            \n            np.seterr(all='raise')\n            ### Evaluo las distancias a cada centroides\n            ### le sumo 0.00001 a cada distancia para evitar division sobre cero\n            distc = []\n            for c in centroids:\n                distc.append(distancia(X_data[element], c, p_dista,covariance_matrix)+0.00001)\n            \n\n            ### Encuentro el centroide al que tiene menor distancia\n            nearest_centroid = np.argmin(distc)\n            \n            ### Asigno el elemento a este cluster\n            etiquetas[element] = nearest_centroid\n            \n            \n            ### Recalculo el centroide \n            centroids[nearest_centroid] = np.mean(X_data[np.where(etiquetas==nearest_centroid)], axis=0)   \n        \n        centroids = np.array(centroids)\n\n\n    ### Guardar grados de pertenencia a cada cluster\n    for element in range(numdata):\n        ### Evaluo las distancias a cada centroides\n        ### le sumo 0.00001 a cada distancia para evitar division sobre cero\n        distc = []\n        for c in centroids:\n            distc.append(distancia(X_data[element], c, p_dista,covariance_matrix)+0.00001)        \n        grados_pert = list(np.around(1/(distc/sum(distc))/sum(1/(distc/sum(distc))),4))\n        grados_pertenencia.append(grados_pert)\n\n    logger.info('Fin del algoritmo kmeans')\n    return grados_pertenencia,etiquetas,centroids\n\n\ndef plot_clusters_bokeh(list_x, list_y, list_pais, k, etiquetas, grados_pertenencia, \n                        title = 'Title', to_save = True):\n\n    ### Plotear con hover tool\n    \n    ### Colores a usar para cada cluster\n    colores = ['blue', 'yellow', 'red', 'green', 'orange', 'purple']\n\n    \n    ### Creo la herramienta de hover tool\n    hover = HoverTool(tooltips=[\n        (\"pais\",\"@pais\"),\n        (\"index\", \"$index\"),\n        (\"(x,y)\", \"(@x, @y)\"),\n        (\"cluster_id\", \"@cluster_id\"),\n        (\"Pertenencia_clusters\", \"@grados_p\"),\n        ])\n\n    ### Creo la figura\n    p = figure(plot_width=700, plot_height=500, tools=[hover, PanTool(), \n                                                       ResetTool(), BoxZoomTool(), \n                                                       WheelZoomTool()], title=title)\n    \n    ### PLoteo cada cluster\n    for i in range(k):\n        source = ColumnDataSource(data={'x':list_x[np.where(etiquetas==i)], 'y':list_y[np.where(etiquetas==i)], 'pais':list_pais[np.where(etiquetas==i)],'grados_p':grados_pertenencia[np.where(etiquetas==i)],'cluster_id':etiquetas[np.where(etiquetas==i)]})\n        p.circle('x','y', size=12, \n                 fill_color=colores[i], source=source)\n\n    ### Ploteo centroides\n    #p.square(centroids_pca[:,0], centroids_pca[:,1], size=15,    fill_color='black')\n    \n    ### Labels (componentes principales)\n    p.xaxis.axis_label = 'Componente principal 1'\n    p.yaxis.axis_label = 'Componente principal 2'\n    #p.xaxis.axis_label = datos.columns[-2]\n    #p.yaxis.axis_label = datos.columns[-1]\n    \n    if to_save:\n    ### Guardo el resultado\n        output_file('outputs/ClustersGenerados/cluster_inicial_'+title+'.html')\n        save(p)\n    \n    return None\n\ndef plot_cluster_bokeh_cambios(X_data_pca, list_x, list_y, list_xv, list_yv, k, \n                               cambios_variables, list_pais, grados_pertenencia, \n                               etiquetas, etiquetas_prev, centroids, \n                               centroids_viej, centroids_pca, title = 'Title',\n                               to_save = True):\n    \n    ### Hover tool para los datos\n    hover = HoverTool(tooltips=[\n                                (\"pais\",\"@pais\"),\n                                (\"index\", \"$index\"),\n                                (\"(x,y)\", \"(@x, @y)\"),\n                                (\"(Cambio_x,Cambio_y)\", \"(@xv, @yv)\"),    \n                                (\"cluster_id\", \"@cluster_id\"),\n                                (\"Pertenencia_clusters\", \"@grados_p\"),\n                                ])\n    \n    ### Colores a usar para cada cluster\n    colores = ['blue', 'yellow', 'red', 'green', 'orange', 'purple']\n    \n    ### Crear la figura\n    p = figure(plot_width=700, plot_height=500, tools=[hover, PanTool(), \n                                                       ResetTool(), \n                                                       BoxZoomTool(), \n                                                       WheelZoomTool()],\n                                                       title=title)\n    \n    ### PLoteo cada conjunto\n    for i in range(k):\n        source = ColumnDataSource(data={'x':list_x[np.where(etiquetas==i)], \n                                        'y':list_y[np.where(etiquetas==i)], \n                                        'xv':list_xv[np.where(etiquetas==i)], \n                                        'yv': list_yv[np.where(etiquetas==i)],\n                                        'pais':list_pais[np.where(etiquetas==i)],\n                                        'grados_p':grados_pertenencia[np.where(etiquetas==i)],\n                                        'cluster_id':etiquetas[np.where(etiquetas==i)]})\n        p.circle('x','y', size=12, \n                 fill_color=colores[i], source=source)\n    \n    \n    ### Veo cuales cambiaron de cluster\n    etiquetas_cambios = np.where(etiquetas_prev-etiquetas != 0)\n    etiqs = etiquetas[etiquetas_cambios]\n    \n    ### PLoteo los elementos de cada conjunto que cambiaron de cluster\n    \n    ### Listas para los elementos que cambiaron de cluster\n    X_data_cambios = X_data_pca[etiquetas_cambios]\n    list_x = X_data_cambios[:,0]\n    list_y = X_data_cambios[:,1]\n    list_xv = cambios_variables[:,0]\n    list_yv = cambios_variables[:,1]\n    list_pais = list_pais[etiquetas_cambios]\n    grados_pertenencia = grados_pertenencia[etiquetas_cambios]\n    \n    ## Plotear elementos que cambiaron de cluster\n    for i in range(k):\n        source = ColumnDataSource(data={'x':list_x[np.where(etiqs==i)], \n                                        'y':list_y[np.where(etiqs==i)], \n                                        'xv':list_xv[np.where(etiqs==i)], \n                                        'yv': list_yv[np.where(etiqs==i)],\n                                        'pais':list_pais[np.where(etiqs==i)],\n                                        'grados_p':grados_pertenencia[np.where(etiqs==i)],\n                                        'cluster_id':etiqs[np.where(etiqs==i)]})\n        p.square('x','y', size=6, \n                 fill_color='white', source=source)\n    \n    \n    \n    ### Ploteo centroides\n    \n    ### Listas para centroiodes\n    cambios_centroids = centroids_viej - centroids\n    list_x = centroids_pca[:,0]\n    list_y = centroids_pca[:,1]\n    list_xv = cambios_centroids[:,0]\n    list_yv = cambios_centroids[:,1]\n    \n    # Plotar centroids    \n    source = ColumnDataSource(data={'x':list_x, 'y':list_y, 'xv':list_xv, 'yv': list_yv})\n    #    p.square('x','y', size=15,             fill_color='black',source=source)\n    \n    ### Labels de la grafica (componentes principales)\n    p.xaxis.axis_label = 'Componente principal 1'\n    p.yaxis.axis_label = 'Componente principal 2'\n    #p.xaxis.axis_label = datos.columns[-2]\n    #p.yaxis.axis_label = datos.columns[-1]\n    \n    \n    if to_save:\n        ### Guardar resultados\n        output_file('outputs/ClustersGenerados/cluster'+title+'.html')\n        save(p)\n    \n    return None\n\n\n\n\n\n\n\n\n\n\n### Para ploteo de datos con estilo de gapminder\ndef gapminder_plot_bokeh(datos_e, datos_pca, year_i, X_data_df, grad_per,\n                         etiquetas_glo, periodos_incluir, k, imp_periods_var,\n                         centroids_ite, scaler_es,\n                         title = 'Titulo',\n                         xlabel='Eje x',\n                         ylabel='Eje y'):\n    \n    \n\n    \n    \n    \n    ### Lista years\n    years_plot = []\n    for o in range(periodos_incluir+1):\n        years_plot.append(year_i + o)\n        \n    ### Dataframes necesarias\n    pca1 = pd.DataFrame(columns = years_plot)\n    pca2 = pd.DataFrame(columns = years_plot)\n    \n    ### PCA de cada year\n    for year in years_plot:\n        filtro = datos_e['Date']==year\n        \n        ### Los que usare para el PCA seran\n        X_data_pca_y = np.array(datos_pca[filtro])\n        \n        pca1[year] =  X_data_pca_y[:,0]\n        pca2[year] =  X_data_pca_y[:,1]\n    \n    ### Nombres de los individuos\n    pca1.index = X_data_df.country\n    pca2.index = X_data_df.country\n    \n    ### Grados de pertenencia\n    grados_pert = pd.DataFrame(columns = years_plot)\n    \n    \n    ##### Grados de pertenencia de cada year\n    coun = 0\n    for year in years_plot:    \n        grados_pert[year] =  np.max(grad_per[coun], axis=1)*40  ### Aumento escala para que se vean bien\n        coun = coun+1\n    grados_pert.index = X_data_df.country\n    \n     \n    ##### Cluster al que pertenece cada dato en cada periodo de tiempo\n    etiqs_plot = []\n    couu = 0\n    for year in years_plot:\n        eti = pd.DataFrame()\n        eti['region'] = [str(i)[0] for i in list(etiquetas_glo[couu])] ### Solo 1 caracter\n        eti.index = X_data_df.country\n        \n        etiqs_plot.append(eti)\n        couu = couu+1\n    \n    \n    ##### Regions_list son los id de los cluster\n    regions_list = []\n    for cu in range(k):\n        regions_list.append(str(cu))\n    \n    \n    ### fertility df seria componente principal 1\n    ### life expectancy df seria componente principal 2\n    ### population_df_size es el maximo grado de pertenencia\n    ### regions_df es el cluster id al que se asigno cada uno\n    ### years es la lista de years a modelar\n    ### regions list seria el \"nombre \" de cada cluster (top variables mas importantes)\n    \n    \n    \n    \n    ### Consolidar data\n    df = pd.concat({'Componente_1': pca1,\n                    'Componente_2': pca2,\n                    'Grado_Pertenencia': grados_pert},\n                   axis=1)\n        \n        \n    \n    ### Construir data\n    data = {}\n    \n    counta = 0\n    for year in years_plot:\n        df_year = df.iloc[:,df.columns.get_level_values(1)==year]\n        df_year.columns = df_year.columns.droplevel(1)\n        data[year] = df_year.join(etiqs_plot[counta].region).reset_index().to_dict('series')\n        counta = counta+1\n    \n    \n    source = ColumnDataSource(data=data[years_plot[0]])\n\n\n\n\n    ############### Para las labels ########################\n    \n    #### Numero de variables a plotear\n    num_v_plot = 4\n    \n    #### Nombres variables\n    nomb_v = datos_e.columns[2:]\n    \n    #### Desestandarizar centroides\n    centroids_ito = scaler_es.inverse_transform(centroids_ite)\n    \n    #### Consolidar strings de las legends de cada iteracion\n    strings_legends = []\n    c=0\n    for y in years_plot:\n        esta_iter = []\n        estas_imp = imp_periods_var[c]\n        cc = 0\n        for clu in estas_imp:\n            ### Variables mas importantes\n            orden_v = np.argsort(clu)[::-1][:num_v_plot]\n            \n            ### Construir string\n            stri = ''\n            \n            ### Numero observaciones cluster\n            stri = stri + 'Num_obs: '+str(len(np.where(etiquetas_glo[c]==cc)[0])) +', '\n            \n            ### Variables importantes\n            for i in orden_v:\n                stri = stri+nomb_v[i][:12]+': ' + str(np.around(centroids_ito[c][cc][i],2))+', '\n            stri=stri[:-2]\n            esta_iter.append(stri)\n            cc=cc+1\n        strings_legends.append(esta_iter)\n        c=c+1\n\n\n\n    #### PLoteos    \n    global plot\n    plot = figure(title=title, y_range=(-5, 7), plot_height=520, plot_width = 900)\n    plot.xaxis.ticker = SingleIntervalTicker(interval=1)\n    plot.xaxis.axis_label = xlabel\n    plot.yaxis.ticker = SingleIntervalTicker(interval=20)\n    plot.yaxis.axis_label = ylabel\n    \n\n    label = Label(x=1.1, y=18, text=str(years_plot[0]), text_font_size='70pt', text_color='#eeeeee')\n    plot.add_layout(label)\n    \n    color_mapper = CategoricalColorMapper(palette=Spectral6, factors=regions_list)\n    global r\n    \n    r = plot.circle(\n        x='Componente_1',\n        y='Componente_2',\n        size='Grado_Pertenencia',\n        source=source,\n        fill_color={'field': 'region', 'transform': color_mapper},\n        fill_alpha=0.8,\n        line_color='#7c7e71',\n        line_width=0.5,\n        line_alpha=0.5,\n#        legend_group='region',\n    )\n    \n    from bokeh.models import Legend, LegendItem\n    \n    global legend   \n    \n    items_son=[]\n    co = 0\n    for a in strings_legends[0]:\n        color_ =  list(etiquetas_glo[0]).index(co)\n        items_son.append(LegendItem(label=a, renderers=[r], index=color_))\n        co=co+1\n        \n    legend = Legend(items=items_son)\n    plot.add_layout(legend)    \n    \n\n    plot.add_tools(HoverTool(tooltips=\"@country\", show_arrow=False, point_policy='follow_mouse'))    \n\n\n    def animate_update():\n        year = slider.value + 1\n        if year > years_plot[-1]:\n            year = years_plot[0]\n        slider.value = year\n    \n    \n    def slider_update(attrname, old, new):\n        year = slider.value\n        label.text = str(year)\n        source.data = data[year]\n        pos = years_plot.index(year)\n        global legend\n        global r\n        global plot\n\n    \n        items_son=[]\n        bo = 0\n        for a in strings_legends[pos]:\n            color_ =  list(etiquetas_glo[pos]).index(bo)\n            items_son.append(LegendItem(label=a, renderers=[r], index=color_))\n            bo=bo+1\n        legend.items = items_son\n        plot.add_layout(legend)   \n        \n\n        \n    slider = Slider(start=years_plot[0], end=years_plot[-1], value=years_plot[0], step=1, title=\"Year\")\n    slider.on_change('value', slider_update)\n    \n    callback_id = None\n    \n    def animate():\n        global callback_id\n        if button.label == '► Play':\n            button.label = '❚❚ Pause'\n            callback_id = curdoc().add_periodic_callback(animate_update, 1000)\n        else:\n            button.label = '► Play'\n            curdoc().remove_periodic_callback(callback_id)\n    \n    button = Button(label='► Play', width=60)\n    button.on_click(animate)\n    \n    layout_plot = layout([\n        [plot],\n        [slider, button],\n    ])\n    \n    \n    curdoc().add_root(layout_plot)\n    curdoc().title = \"Gapminder\"\n\n    return None"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["import os\nimport numpy as np\nimport pandas as pd\nfrom  sklearn.preprocessing import StandardScaler as StdScaler\nimport pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark import SparkContext\nfrom pyspark.sql.types import *\nimport pyspark.sql.functions as f\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml.clustering import KMeans\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.feature import PCA\nfrom pyspark.ml.feature import StandardScaler as SparkStdScaler\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["## Loading spark session\n#sc = pyspark.SparkContext()\nsc = pyspark.SparkContext.getOrCreate()\nspark = SparkSession(sc)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["spark.conf.set(\"spark.sql.execution.arrow.enabled\",\"false\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["### Leemos los datos\ndatos = spark.read.format(\"csv\")\\\n        .option(\"header\", \"true\")\\\n        .option(\"inferSchema\", \"true\")\\\n        .load(\"dbfs:/mnt/mountblob/data_gapminder_proc2.csv\")\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["### Nombres variables\n### Variable names\nnomb_vars = datos.columns[2:]\n\n### removing . from variable names\nfor n in nomb_vars:\n    datos = datos.withColumnRenamed(n,n.replace(\".\",\"\"))\n    "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["datos.toPandas().head(3)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n      <th>Date</th>\n      <th>population_growth_annual_percent</th>\n      <th>population_total</th>\n      <th>children_per_woman_total_fertility</th>\n      <th>population_density_per_square_km</th>\n      <th>total_gdp_us_inflation_adjusted</th>\n      <th>gdp_per_capita_yearly_growth</th>\n      <th>gdppercapita_us_inflation_adjusted</th>\n      <th>children_and_elderly_per_100_adults</th>\n      <th>life_expectancy_years</th>\n      <th>child_mortality_0_5_year_olds_dying_per_1000_born</th>\n      <th>gdp_total_yearly_growth</th>\n      <th>income_per_person_gdppercapita_ppp_inflation_adjusted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Albania</td>\n      <td>1980</td>\n      <td>2.05</td>\n      <td>2680000</td>\n      <td>3.62</td>\n      <td>97.9</td>\n      <td>5.640000e+09</td>\n      <td>0.706</td>\n      <td>2110.0</td>\n      <td>70.2</td>\n      <td>72.3</td>\n      <td>77.8</td>\n      <td>2.81</td>\n      <td>4390.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Albania</td>\n      <td>1981</td>\n      <td>2.00</td>\n      <td>2740000</td>\n      <td>3.53</td>\n      <td>99.8</td>\n      <td>5.960000e+09</td>\n      <td>0.536</td>\n      <td>2190.0</td>\n      <td>68.9</td>\n      <td>72.4</td>\n      <td>72.0</td>\n      <td>2.56</td>\n      <td>4400.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Albania</td>\n      <td>1982</td>\n      <td>2.11</td>\n      <td>2790000</td>\n      <td>3.45</td>\n      <td>102.0</td>\n      <td>6.140000e+09</td>\n      <td>0.550</td>\n      <td>2210.0</td>\n      <td>67.8</td>\n      <td>72.5</td>\n      <td>66.8</td>\n      <td>2.49</td>\n      <td>4410.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["#### Preprocesamiento de datos\n#datos = funciones_pyspark.data_preprocessing(datos, alpha_outlier_detection =0.96, \ndatosp = datos.toPandas()\ndatos = data_preprocessing(datosp, alpha_outlier_detection =0.96, \n                                     columns_not_numeric = {'country','Date'},\n                                     column_id = 'country')\n\n### Estandarizo todos los datos\ndatos_e = datos.copy()\nscaler_es = StdScaler()\nscaler_es.fit(datos_e[datos_e.columns[2:]])\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int32, float64 were all converted to float64 by StandardScaler.\n  return self.partial_fit(X, y)\nOut[9]: StandardScaler(copy=True, with_mean=True, with_std=True)</div>"]}}],"execution_count":10},{"cell_type":"code","source":["datosp.head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n      <th>Date</th>\n      <th>population_growth_annual_percent</th>\n      <th>population_total</th>\n      <th>children_per_woman_total_fertility</th>\n      <th>population_density_per_square_km</th>\n      <th>total_gdp_us_inflation_adjusted</th>\n      <th>gdp_per_capita_yearly_growth</th>\n      <th>gdppercapita_us_inflation_adjusted</th>\n      <th>children_and_elderly_per_100_adults</th>\n      <th>life_expectancy_years</th>\n      <th>child_mortality_0_5_year_olds_dying_per_1000_born</th>\n      <th>gdp_total_yearly_growth</th>\n      <th>income_per_person_gdppercapita_ppp_inflation_adjusted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Albania</td>\n      <td>1980</td>\n      <td>2.05</td>\n      <td>2680000</td>\n      <td>3.62</td>\n      <td>97.9</td>\n      <td>5.640000e+09</td>\n      <td>0.706</td>\n      <td>2110.0</td>\n      <td>70.2</td>\n      <td>72.3</td>\n      <td>77.8</td>\n      <td>2.81</td>\n      <td>4390.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Albania</td>\n      <td>1981</td>\n      <td>2.00</td>\n      <td>2740000</td>\n      <td>3.53</td>\n      <td>99.8</td>\n      <td>5.960000e+09</td>\n      <td>0.536</td>\n      <td>2190.0</td>\n      <td>68.9</td>\n      <td>72.4</td>\n      <td>72.0</td>\n      <td>2.56</td>\n      <td>4400.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Albania</td>\n      <td>1982</td>\n      <td>2.11</td>\n      <td>2790000</td>\n      <td>3.45</td>\n      <td>102.0</td>\n      <td>6.140000e+09</td>\n      <td>0.550</td>\n      <td>2210.0</td>\n      <td>67.8</td>\n      <td>72.5</td>\n      <td>66.8</td>\n      <td>2.49</td>\n      <td>4410.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Albania</td>\n      <td>1983</td>\n      <td>2.12</td>\n      <td>2840000</td>\n      <td>3.38</td>\n      <td>104.0</td>\n      <td>6.210000e+09</td>\n      <td>0.584</td>\n      <td>2180.0</td>\n      <td>66.8</td>\n      <td>72.6</td>\n      <td>61.9</td>\n      <td>2.54</td>\n      <td>4430.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Albania</td>\n      <td>1984</td>\n      <td>2.10</td>\n      <td>2900000</td>\n      <td>3.32</td>\n      <td>106.0</td>\n      <td>6.130000e+09</td>\n      <td>0.569</td>\n      <td>2110.0</td>\n      <td>65.8</td>\n      <td>72.8</td>\n      <td>57.4</td>\n      <td>2.68</td>\n      <td>4440.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":11},{"cell_type":"code","source":["datos_new = spark.createDataFrame(datos)\n### Vector Assembler in pyspark\nassembler = VectorAssembler(inputCols=datos_new.columns[2:],outputCol=\"features\")\ndatos_new = assembler.transform(datos_new)\n\n### Standard Scaler in pyspark\nscaler = SparkStdScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=True)\nscaler = scaler.fit(datos_new)\ndatos_new = scaler.transform(datos_new)\n\ndatos_e_cols = list(datos_e.columns)\n\nscaled_pdf = datos_new.select(\"scaledFeatures\").toPandas()\nfor i in range(2,len(datos_e_cols)):\n    datos_e[datos_e_cols[i]] = scaled_pdf[\"scaledFeatures\"].apply(lambda x:x[i-2])\n    \n### PCA\npca = PCA(k=2, inputCol=\"scaledFeatures\", outputCol=\"pcaFeatures\")\npca = pca.fit(datos_new)\n\ndatos_new = pca.transform(datos_new)\npca_pdf = datos_new.select('pcaFeatures').toPandas()\n\npca_pdf['pcaFeatures_1'] = pca_pdf['pcaFeatures'].apply(lambda x:x[0])\npca_pdf['pcaFeatures_2'] = pca_pdf['pcaFeatures'].apply(lambda x:x[1])\n\n# print(pca_pdf.head())\n\ndatos_pca = np.array(pca_pdf[['pcaFeatures_1','pcaFeatures_2']])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12},{"cell_type":"code","source":["datos_pca"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[12]: array([[-0.25913151, -0.65697817],\n       [-0.16360253, -0.68711285],\n       [-0.13473097, -0.69526264],\n       ...,\n       [-1.6995732 ,  0.09751816],\n       [-1.75564351,  0.00659415],\n       [-1.68608419, -0.0305482 ]])</div>"]}}],"execution_count":13},{"cell_type":"code","source":["### Fijar seed aleatoria\nnp.random.seed(1)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"code","source":["##### Inicio tomando los del primer year\nyear_i = min(datos_e['Date'].values.tolist())   ### Year inicial a considerar\nfiltro = datos_e['Date']==year_i\nX_data_df = datos_e[filtro].reset_index(drop=True)\nX_data = np.array(X_data_df[X_data_df.columns[2:]])\n\n\n### Numero de periodos que incluire en el estudio, sin incluir el inicial\nperiodos_incluir = max(datos_e['Date']) - min(datos_e['Date']) - 1\n\n### Los que usare para el PCA seran\nX_data_pca = np.array(datos_pca[filtro])\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":15},{"cell_type":"code","source":["#### Lista donde ire guardando las listas de grados de pertenencia \ngrad_per = []\n\n### Lista donde ire guardando las etiquetas asignadas del cluster\netiquetas_glo = []\n\n### Lista donde ire guardando las variables mas importantes por cluster y por periodo\nimp_periods_var = []\n\n### Lista donde ire guardando los centroides de cada iteracion\ncentroids_ite = []\n\n\n## Numero de observaciones en cada periodo\nnumdata = len(X_data)\n  \n\n### Define cantidad de clusters, numero maximo de iteraciones, y la distancia\n### que se utilizara en el metodo de kmeans\nk = 3\nnumiter = 5\np_dista = 2   ### 0 para mahalanobis\n\n\n#### Inicializar los centroides\ncentroids = init_centroids(X_data,k)\n\ncentroids_arr = np.array(centroids)\ncentroids_map = map(lambda x: (int(x[0]), Vectors.dense(x[0:])), centroids_arr)\ncentroids_spark_df = spark.createDataFrame(centroids_map,schema=[\"ind\", \"scaledFeatures\"])\ncentroids_spark_df = pca.transform(centroids_spark_df)\n\npca_cent_pdf = centroids_spark_df.select('pcaFeatures').toPandas()\npca_cent_pdf['pcaFeatures_1'] = pca_cent_pdf['pcaFeatures'].apply(lambda x:x[0])\npca_cent_pdf['pcaFeatures_2'] = pca_cent_pdf['pcaFeatures'].apply(lambda x:x[1])\n\ncentroids_pca = np.array(pca_cent_pdf[['pcaFeatures_1','pcaFeatures_2']])\n\n\nprint(centroids_pca)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[[-5.13248312e-01 -6.90551998e-01]\n [-2.47676391e+00 -1.72798381e-03]\n [-2.63227093e+00  9.48617401e-02]]\n</div>"]}}],"execution_count":16},{"cell_type":"code","source":["### Para la fase 2 de las importancias\ncentroids_p = centroids.copy()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":17},{"cell_type":"code","source":["### Aplicar kmeans (version vieja)\ngrados_pertenencia20,etiquetas20,centroids20 = kmeans_old(X_data,\n                                                          numiter,\n                                                          centroids,\n                                                          p_dista = p_dista)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18},{"cell_type":"code","source":["### Aplicar k means de pyspark (version nueva)\nfrom pyspark.ml.clustering import KMeans\n\n### Transformar el numyp array a un spark dataframe\npand_x = pd.DataFrame(X_data)\nX_data_sp = spark.createDataFrame(pand_x)\n\n### Nombre de columnas\nlisi=[]\nfor i in pand_x.columns:\n    lisi.append(str(i))\n\n### Transformar a assembler\nvecAssembler = VectorAssembler(inputCols=lisi,outputCol=\"features\")\ndf_kmeans = vecAssembler.transform(X_data_sp).select('features')\n\n\n# Trains a k-means model.\nkmeans = KMeans().setK(k).setSeed(40)\n#kmeans = KMeans().setK(k)\nmodel = kmeans.fit(df_kmeans)\n\n### Predecir etiquetas\npredictions = model.transform(df_kmeans)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":19},{"cell_type":"code","source":["\n### Recuperar las 3 salidas en el mismo formato del k means anterior\n\n### Etiquetas\netiquetas = predictions.toPandas()['prediction'].values\n\n### Centroids\ncentroids = np.array(model.clusterCenters())\n\n### Grados pertenencia: no es salida de kmeans de pyspark, la pongo en una cte, solo se usa para plot, no importara\ngrados_pertenencia = []\nfor ji in range(len(X_data)):\n    lio=[]\n    for li in range(k):\n        lio.append(0.5)\n    grados_pertenencia.append(lio) "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":20},{"cell_type":"code","source":["### Guardo grados de pertenencia\ngrad_per.append(grados_pertenencia.copy())\n\n### Guardo etiquetas\netiquetas_glo.append(etiquetas.copy())\n\n### Guardo centroids\ncentroids_ite.append(centroids.copy())\n\n### Variable global donde ire guardando la importancia de las variables en cada \n### iteracion\nimp_iters = []\n\n\n### Obtener la importancia de las variables de cada cluster (de mayor a menor)\nimportancias_cluster = []\n\n### Para cada cluster\nfor clu in range(k):\n    ### Dejo solo las observaciones de cada cluster\n    datax_i = pd.DataFrame(X_data)\n    datay_i = etiquetas.copy()\n    #### Solo clasifico binario si si pertence o no a cada cluster\n    distintos_cluster = np.where(datay_i!=clu)\n    ### Lo que no pertenece al cluster, lo pongo en -1\n    datay_i[distintos_cluster] = -1\n    datay_i = pd.DataFrame(datay_i)\n    ### Calcular relevancias\n    relevancias, _ = variables_relevantes_arbol(datax_i, datay_i, 0)\n#     print(relevancias)\n    importancias_cluster.append(relevancias)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":21},{"cell_type":"code","source":["##### Calculo los promedios de importancia de cada variable\nimp_clus_prom =  np.mean(importancias_cluster, axis=0)\n\n### Guardo las importancias de esta iteracion\nimp_iters.append(imp_clus_prom)\n\n\n### Guardo importancias generales (para el plot)\nimp_periods_var.append(importancias_cluster)\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":22},{"cell_type":"code","source":["X_data.shape"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[22]: (108, 9)</div>"]}}],"execution_count":23},{"cell_type":"code","source":["\n###############################################################################\n################## Ahora, empiezo a iterar para t >=2 #########################\n###############################################################################\n\n#X_data_df = datos_e[filtro].reset_index(drop=True)\n#X_data = np.array(X_data_df[X_data_df.columns[2:]])\n#periodos_incluir = 5\nfor periodos in range(periodos_incluir):\n    \n    print(periodos)\n    ### Guardo la X_data anterior\n    X_data_viej = X_data.copy()\n    centroids_viej = centroids.copy()\n    \n\n    ### Los datos para este year ya serian\n    X_data_df = datos_e[datos_e['Date']==year_i+1+periodos]\n    X_data = np.array(X_data_df[X_data_df.columns[2:]])\n    \n    \n\n    #### Obtener los 2 componentes principales de los datos para plotear estos\n    X_data_pca = np.array(datos_pca[datos_e['Date']==year_i+1+periodos])\n    \n    ### Calulo los cambios en las variables\n    cambios_variables = X_data_viej - X_data    \n    \n    ###########################################################################\n    ######################### Ponderacion dinamica ############################\n    ###########################################################################\n    \n    ### Pondero X_data\n    X_data_ori = X_data.copy()  ### X data original (sin ponderacion)\n    \n    \n    ### Obtengo la importancia promedio de cada variable (promedio de todas las\n    ### iteraciones)\n    importancia_prom = np.mean(imp_iters, axis=0)\n    \n    ### Rankeo las variables de menor a mayor importancia\n    rank_variables = np.argsort(importancia_prom)\n    rankpeso_variables = np.zeros(len(rank_variables))\n    \n    cont = 0\n    for i in rank_variables:\n        rankpeso_variables[i] = (cont+1)/len(rank_variables)\n        cont= cont+1\n\n    #### Usar rankings o usar los promedios para el peso\n    peso_variables = importancia_prom.copy()*100  ### Escalarlos con 100 para reducir errores numericos\n\n    \n    ### Escalo entonces la X para cambiar los pesos (segun las importancias)\n    X_data_pond = X_data.copy()\n    for peso in range(len(peso_variables)):\n        X_data_pond[:,peso] = X_data_pond[:,peso] * peso_variables[peso]\n\n    \n    ###########################################################################\n    ######################## K means para los plots ###########################\n    ###########################################################################\n    \n    ### Etiquetas actuales de cada elemento para cada cluster\n    etiquetas_prev = etiquetas.copy()\n    \n    ###########################################################################\n    #################### Clusters con k means ponderado #######################\n    ###########################################################################\n    \n#    grados_pertenencia,etiquetas,centroids = kmeans_old(X_data_pond,\n#                                                              numiter,\n#                                                              centroids,\n#                                                              p_dista = p_dista,\n#                                                              etiquetas = etiquetas)\n\n\n    \n    ### Transformar el numyp array a un spark dataframe\n    pand_x = pd.DataFrame(X_data_pond)\n    X_data_sp = spark.createDataFrame(pand_x)\n\n    ### Nombre de columnas\n    lisi=[]\n    for i in pand_x.columns:\n        lisi.append(str(i))\n\n    ### Transformar a assembler\n    vecAssembler = VectorAssembler(inputCols=lisi,outputCol=\"features\")\n    df_kmeans = vecAssembler.transform(X_data_sp).select('features')\n\n\n    # Trains a k-means model.\n    kmeans = KMeans().setK(k).setSeed(periodos)\n   #kmeans = KMeans().setK(k)\n    \n    model = kmeans.fit(df_kmeans)\n\n    ### Predecir etiquetas\n    predictions = model.transform(df_kmeans)    \n\n\n\n    ### Recuperar las 3 salidas en el mismo formato del k means anterior\n\n    ### Etiquetas\n    etiquetas = predictions.toPandas()['prediction'].values\n\n    ### Centroids\n    centroids = np.array(model.clusterCenters())\n\n    ### Grados pertenencia: no es salida de kmeans de pyspark, la pongo en una cte, solo se usa para plot, no importara\n    grados_pertenencia = []\n    for ji in range(len(X_data_pond)):\n        lio=[]\n        for li in range(k):\n            lio.append(0.5)\n        grados_pertenencia.append(lio)     \n\n\n\n\n    ### Guardo grados de pertenencia\n    grad_per.append(grados_pertenencia.copy())\n\n    ### Guardo etiquetas\n    etiquetas_glo.append(etiquetas.copy())\n\n    ### Guardo centroids\n    centroids_ite.append(centroids.copy()*(1/peso_variables))\n\n\n\n\n\n    ###### Esta importancia la necesito para los labels\n    ### Obtener la importancia de las variables de cada cluster (de mayor a menor)\n    importancias_cluster = []\n    ### Para cada cluster\n    for clu in range(k):\n        ### Dejo solo las observaciones de cada cluster\n        datax_i = pd.DataFrame(X_data_pond)\n        datay_i = etiquetas.copy()\n        \n        #### Solo clasifico binario si si pertence o no a cada cluster\n        distintos_cluster = np.where(datay_i!=clu)\n        \n        ### Lo que no pertenece al cluster, lo pongo en -1\n        datay_i[distintos_cluster] = -1\n        datay_i = pd.DataFrame(datay_i)\n        \n        ### Calcular relevancias\n        relevancias, _ = variables_relevantes_arbol(datax_i, datay_i, 0)\n        \n        importancias_cluster.append(relevancias)\n\n    ### Guardo importancias generales (para el plot)\n    imp_periods_var.append(importancias_cluster)\n\n\n    \n    ###########################################################################\n    ################ K means para la seleccion de variables ###################\n    ###########################################################################\n    \n    ###### Para la proxima iteracion, los pesos\n#    grados_pertenencia_p,etiquetas_p,centroids_p = kmeans_old(X_data_ori,\n#                                                                    numiter,\n#                                                                    centroids_p,\n#                                                                    p_dista = p_dista,\n#                                                                    etiquetas = etiquetas)\n\n    \n   \n\n    ### Transformar el numyp array a un spark dataframe\n    pand_x = pd.DataFrame(X_data_ori)\n    X_data_sp = spark.createDataFrame(pand_x)\n\n    ### Nombre de columnas\n    lisi=[]\n    for i in pand_x.columns:\n        lisi.append(str(i))\n\n    ### Transformar a assembler\n    vecAssembler = VectorAssembler(inputCols=lisi,outputCol=\"features\")\n    df_kmeans = vecAssembler.transform(X_data_sp).select('features')\n\n\n    # Trains a k-means model\n    kmeans = KMeans().setK(k).setSeed(periodos)\n    #kmeans = KMeans().setK(k)\n    model = kmeans.fit(df_kmeans)\n\n    ### Predecir etiquetas\n    predictions_p = model.transform(df_kmeans)    \n\n\n    ### Recuperar las 3 salidas en el mismo formato del k means anterior\n\n    ### Etiquetas\n    etiquetas_p = predictions_p.toPandas()['prediction'].values\n\n    ### Centroids\n    centroids_p= np.array(model.clusterCenters())\n  \n\n    \n    #####################################\n\n\n    \n    \n    \n    ### Obtener la importancia de las variables de cada cluster (de mayor a menor)\n    importancias_cluster = []\n    ### Para cada cluster\n    for clu in range(k):\n        ### Dejo solo las observaciones de cada cluster\n        datax_i = pd.DataFrame(X_data_ori)\n        datay_i = etiquetas_p.copy()\n        \n        #### Solo clasifico binario si si pertence o no a cada cluster\n        distintos_cluster = np.where(datay_i!=clu)\n        \n        ### Lo que no pertenece al cluster, lo pongo en -1\n        datay_i[distintos_cluster] = -1\n        datay_i = pd.DataFrame(datay_i)\n        \n        \n        ### Calcular relevancias\n        relevancias, _ = variables_relevantes_arbol(datax_i, datay_i, 0)\n        \n        importancias_cluster.append(relevancias)\n    \n    ### Calculo los promedios de importancia de cada variable\n    imp_clus_prom =  np.mean(importancias_cluster, axis=0)\n    \n    ### Guardo las importancias de esta iteracion\n    imp_iters.append(imp_clus_prom)\n\n"],"metadata":{"scrolled":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n</div>"]}}],"execution_count":24},{"cell_type":"code","source":["#centroids_pca[5]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":25},{"cell_type":"code","source":["centroids_ite"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[25]: [array([[ 0.63665782, -0.0462982 , -0.35238024, -0.2650169 , -0.39141872,\n          0.71209344, -0.20124614,  0.24457252,  0.92367104],\n        [ 0.90206974, -0.29907528, -0.33189928, -0.34575716, -0.58537471,\n          1.07908391, -1.25991171,  1.77084195, -0.88118228],\n        [-0.92507622, -0.11325886,  0.39434093,  0.27108047,  0.59302813,\n         -0.6158407 ,  0.60525284, -0.70563338, -0.41897428]]),\n array([[-0.62048554, -0.17337755,  0.23144048,  0.11309791,  0.3576985 ,\n         -0.44777965,  0.5267452 , -0.63155911, -0.1826226 ],\n        [ 0.81662311, -0.28147347, -0.26745792, -0.36373592, -0.62193398,\n          1.07790686, -1.55002839,  2.20395045, -0.28084711],\n        [ 0.97067806, -0.01452329, -0.42349235, -0.26055858, -0.47730618,\n          1.01838842, -0.47330459,  0.5569525 ,  0.14998199]]),\n array([[ 0.95948364, -0.22340361, -0.28411054, -0.36178607, -0.6171959 ,\n          1.12122649, -1.42125871,  2.0277309 , -0.15037955],\n        [ 0.75151825, -0.0555747 , -0.3464453 , -0.25698235, -0.46404515,\n          0.99494873, -0.33756414,  0.32442822, -0.04446125],\n        [-0.59706445, -0.13727985,  0.22657571,  0.1535373 ,  0.41580797,\n         -0.62449686,  0.58577131, -0.66284485, -0.71531937]]),\n array([[ 0.77502486, -0.0037405 , -0.38180543, -0.24792535, -0.4647161 ,\n          0.95795166, -0.32578723,  0.28746074, -0.16965907],\n        [-0.63861139, -0.15455726,  0.24572468,  0.14142917,  0.38804605,\n         -0.60898171,  0.60034114, -0.67574758, -0.31014106],\n        [ 1.00630847, -0.21060722, -0.28510184, -0.36162495, -0.6184338 ,\n          1.14776881, -1.40799504,  1.9462869 , -0.63500692]]),\n array([[-0.72469681, -0.17064039,  0.2466132 ,  0.1360957 ,  0.38086879,\n         -0.60121068,  0.59738167, -0.67380912,  0.10784314],\n        [ 1.02635109, -0.19847364, -0.27425035, -0.36137447, -0.61898705,\n          1.15270024, -1.38944374,  1.89936867, -0.34154821],\n        [ 0.89561157,  0.05255044, -0.40616459, -0.23495103, -0.45871879,\n          0.94052311, -0.29364643,  0.25528929, -0.00745626]]),\n array([[ 1.03868500e+00, -1.85880516e-01, -2.62932893e-01,\n         -3.60322075e-01, -6.18355419e-01,  1.15215231e+00,\n         -1.36340058e+00,  1.85296603e+00,  1.60937186e-01],\n        [-1.03629806e+00, -1.07723287e-01,  3.37793448e-01,\n          3.12994019e-01,  6.83222884e-01, -9.06018572e-01,\n          6.74897410e-01, -7.47673634e-01, -2.63158020e-03],\n        [ 6.78074910e-01, -4.21955628e-02, -2.88819207e-01,\n         -2.52203514e-01, -4.42142911e-01,  6.86551259e-01,\n         -6.55072677e-02,  1.18664045e-03, -1.64498118e-01]]),\n array([[ 1.04898382, -0.17298072, -0.25088629, -0.36038047, -0.61868045,\n          1.18356735, -1.31452506,  1.8029543 ,  0.04968394],\n        [-0.90710628, -0.15162769,  0.32375466,  0.21971723,  0.51960609,\n         -0.77443284,  0.65790055, -0.71894451,  0.16518035],\n        [ 0.80087375,  0.03916697, -0.37773403, -0.22838593, -0.43579418,\n          0.76962327, -0.10995403,  0.0447053 , -0.17608396]]),\n array([[ 1.04781210e+00, -1.59981276e-01, -2.38753900e-01,\n         -3.60536404e-01, -6.19100003e-01,  1.20037075e+00,\n         -1.29954132e+00,  1.75294256e+00, -1.79726360e-01],\n        [ 7.77914331e-01,  5.56561134e-02, -3.71293218e-01,\n         -2.22937385e-01, -4.37239611e-01,  7.27678947e-01,\n         -8.14328580e-02,  2.13109755e-04, -7.99095602e-03],\n        [-9.45794658e-01, -1.48706961e-01,  3.29218707e-01,\n          2.40498443e-01,  5.45837239e-01, -8.02177579e-01,\n          6.79577704e-01, -7.31511276e-01,  9.57815678e-02]]),\n array([[-1.04410953, -0.05654604,  0.42553666,  0.51289339,  0.98676567,\n         -1.0886294 ,  0.8242727 , -0.83234446,  0.33171139],\n        [ 1.04572102, -0.20246001, -0.29250449, -0.36163729, -0.58904625,\n          1.19429538, -1.1340818 ,  1.37203116,  0.09503695],\n        [ 0.21178761,  0.04195126, -0.19134718, -0.21982665, -0.41662549,\n          0.31610568,  0.24964339, -0.26114213,  0.00333555]]),\n array([[ 0.93376448, -0.1343256 , -0.24722399, -0.35940473, -0.61379053,\n          1.16883394, -1.20559566,  1.50893342, -0.05311239],\n        [ 0.62766305,  0.03981832, -0.3065291 , -0.21663867, -0.41446141,\n          0.50793652,  0.15708241, -0.1790892 ,  0.27752565],\n        [-1.02399626, -0.09523388,  0.37798737,  0.3675969 ,  0.73156638,\n         -0.91282466,  0.73008858, -0.77790358,  0.14771826]]),\n array([[-0.60217026, -0.04539318,  0.20239397,  0.24357261,  0.43746397,\n         -0.66245899,  0.68502436, -0.67754181, -0.08138826],\n        [ 0.86599089, -0.22593262, -0.40646496, -0.35911647, -0.62546874,\n          1.30864536, -1.59205866,  2.10863169, -0.36863795],\n        [ 0.80619067,  0.01469003, -0.22939262, -0.31981976, -0.5314416 ,\n          0.90701785, -0.41749111,  0.35805206, -0.14552381]]),\n array([[-0.85414946, -0.03505933,  0.43316234,  0.51900756,  0.92833769,\n         -1.08644651,  0.85292775, -0.83263444, -0.56934278],\n        [ 0.77759436, -0.14120221, -0.24842015, -0.35885055, -0.59390938,\n          1.14323311, -1.14926791,  1.33370473, -0.16767648],\n        [ 0.26950478,  0.04814613, -0.22514101, -0.20658373, -0.39795643,\n          0.3085918 ,  0.26378943, -0.31865639,  0.08921041]]),\n array([[ 0.1902723 ,  0.04496657, -0.26356484, -0.21336963, -0.41621563,\n          0.3055942 ,  0.18937844, -0.2500581 ,  0.30981963],\n        [ 0.88158366, -0.10963667, -0.21066144, -0.35678897, -0.59374365,\n          1.19509686, -1.20117709,  1.39089079, -0.65637528],\n        [-0.87644236, -0.04874391,  0.44850272,  0.50407471,  0.90037815,\n         -1.07536682,  0.85516844, -0.83446412, -0.39253922]]),\n array([[-0.56539018, -0.03368866,  0.22030296,  0.25305332,  0.418418  ,\n         -0.69602242,  0.71775905, -0.69854576, -0.18752669],\n        [ 0.79209373, -0.1948548 , -0.39637906, -0.35942659, -0.6265708 ,\n          1.32264662, -1.60259476,  1.95086651, -0.50760293],\n        [ 0.58340489,  0.08692621, -0.20886947, -0.31181654, -0.52877655,\n          0.79226216, -0.40462484,  0.26645386, -0.12925287]]),\n array([[ 0.1097371 ,  0.08515625, -0.23437737, -0.19594342, -0.39156973,\n          0.12430294,  0.2644494 , -0.33352513,  0.13641249],\n        [ 0.76779228, -0.11162522, -0.19826641, -0.35716433, -0.59157418,\n          1.14224647, -1.19119252,  1.26641846, -0.17888141],\n        [-0.97007688, -0.02409748,  0.47054458,  0.55766415,  0.97239873,\n         -1.10506529,  0.89117628, -0.8541562 ,  0.24258693]]),\n array([[ 0.06116995,  0.11454282, -0.21749624, -0.18630325, -0.38931844,\n          0.05616899,  0.31223617, -0.36812342,  0.02498309],\n        [ 0.73424517, -0.11136956, -0.20097831, -0.35689418, -0.58485709,\n          1.08373326, -1.20569419,  1.20492443, -0.18993814],\n        [-1.02171908, -0.02147385,  0.47742515,  0.58449239,  1.01976182,\n         -1.11726381,  0.9065384 , -0.86086193,  0.28073755]]),\n array([[ 0.72014789, -0.11206095, -0.20294433, -0.35612598, -0.57851132,\n          1.0526003 , -1.22427578,  1.14697134,  0.12004193],\n        [-1.06428472,  0.03900934,  0.49410296,  0.84897138,  1.4335273 ,\n         -1.18766454,  1.02381621, -0.91468376, -0.0670316 ],\n        [-0.14436708,  0.08910317, -0.10109454, -0.18990498, -0.37314095,\n         -0.1532358 ,  0.39292305, -0.44660984,  0.28057853]]),\n array([[ 5.75546422e-01, -1.44457141e-03, -1.23606370e-01,\n         -3.33632862e-01, -5.32928767e-01,  6.74351362e-01,\n         -6.17067737e-01,  3.09872004e-01, -4.80530811e-02],\n        [ 7.12982533e-01, -1.63234423e-01, -3.79437462e-01,\n         -3.57329760e-01, -6.18308772e-01,  1.25503551e+00,\n         -1.67866766e+00,  1.79606972e+00, -1.04103636e-01],\n        [-6.42276437e-01,  8.04972182e-02,  1.89580362e-01,\n          2.83333275e-01,  4.43040893e-01, -7.21697493e-01,\n          7.59571804e-01, -7.11223921e-01,  1.43595197e-01]]),\n array([[-1.0642188 ,  0.07704274,  0.56079613,  1.00720072,  1.72832408,\n         -1.19813915,  1.09809457, -0.93097757,  0.07192691],\n        [ 0.69198741, -0.17191447, -0.32518053, -0.35658721, -0.5757997 ,\n          1.02440996, -1.30412818,  1.12115073, -0.21041603],\n        [-0.25742529,  0.14987755,  0.0101947 , -0.18875139, -0.36814914,\n         -0.30934813,  0.4092819 , -0.47905706, -0.05360773]]),\n array([[-0.70891087,  0.095112  ,  0.20186108,  0.30743254,  0.50181606,\n         -0.79875627,  0.79761807, -0.73577408,  0.01492379],\n        [ 0.53696989,  0.04814307, -0.0915585 , -0.32946611, -0.53602895,\n          0.54369451, -0.61132142,  0.24807363,  0.15016495],\n        [ 0.75849952, -0.16571817, -0.36380899, -0.35738589, -0.61076704,\n          1.21385608, -1.64357269,  1.62622325, -0.23054286]]),\n array([[-0.98283768,  0.11429313,  0.47308859,  1.16209331,  1.96613038,\n         -1.21568934,  1.15717124, -0.94197484,  0.27864801],\n        [ 0.67609535, -0.13884541, -0.31998833, -0.34553255, -0.57051928,\n          0.89330891, -1.26813718,  0.96736258,  0.11235114],\n        [-0.38913014,  0.16508641,  0.10867168, -0.18336915, -0.34224514,\n         -0.45648758,  0.51721459, -0.55898521,  0.00921603]]),\n array([[-0.77105905,  0.06391938,  0.26665061,  0.39580496,  0.64757426,\n         -0.92262825,  0.90624139, -0.78202193, -0.27580013],\n        [ 0.69781942, -0.20473712, -0.37215423, -0.35849761, -0.59272577,\n          1.02636567, -1.55868314,  1.15443774,  0.30770792],\n        [ 0.29402353,  0.32627815, -0.01654673, -0.2928412 , -0.51897272,\n          0.20807901, -0.18369523, -0.04455549, -0.06870037]]),\n array([[ 5.23769666e-01,  1.88777893e-01,  6.71318993e-04,\n         -3.16333138e-01, -5.34105387e-01,  3.79401516e-01,\n         -3.95596795e-01,  1.02701400e-01, -2.82404980e-01],\n        [-7.68977195e-01,  1.17139533e-01,  2.18673081e-01,\n          3.56425208e-01,  5.69573020e-01, -9.14088141e-01,\n          8.71541295e-01, -7.70115358e-01, -2.27875031e-01],\n        [ 7.16241375e-01, -1.90930006e-01, -3.48379974e-01,\n         -3.57464061e-01, -5.96244112e-01,  1.03553308e+00,\n         -1.64561053e+00,  1.20366420e+00,  3.64112022e-01]]),\n array([[-0.45239602,  0.16473305,  0.11091562, -0.18224661, -0.30759212,\n         -0.61314985,  0.54874681, -0.59249154,  0.22211618],\n        [ 0.70276901, -0.09123602, -0.3040852 , -0.33991221, -0.56621324,\n          0.84250536, -1.29614704,  0.83949848,  0.16573007],\n        [-0.94262196,  0.15841009,  0.53514242,  1.30471683,  2.0836485 ,\n         -1.23435349,  1.26770486, -0.95750597, -0.2646819 ]]),\n array([[-0.94576795,  0.16222056,  0.54222772,  1.34774085,  2.15566551,\n         -1.23531653,  1.2987426 , -0.96029247, -0.02307517],\n        [ 0.70895183, -0.0779184 , -0.29488234, -0.33550241, -0.56337302,\n          0.808909  , -1.2654049 ,  0.77490601,  0.53150747],\n        [-0.46719272,  0.17572317,  0.11886206, -0.16991305, -0.29276163,\n         -0.67079066,  0.56091847, -0.60322177,  0.49919241]]),\n array([[ 0.71547814, -0.07960212, -0.29304946, -0.33449355, -0.55912632,\n          0.75583668, -1.20358395,  0.67220502,  0.53929976],\n        [-0.49683992,  0.20232731,  0.13917054, -0.15517299, -0.27369422,\n         -0.74268277,  0.62183765, -0.62528969,  0.3636415 ],\n        [-0.93172114,  0.16606163,  0.5467431 ,  1.3826849 ,  2.21036197,\n         -1.23700185,  1.32648846, -0.9632149 , -0.07513541]]),\n array([[-0.90811362,  0.16995372,  0.55432183,  1.43077805,  2.2851138 ,\n         -1.23266817,  1.3575262 , -0.96572955,  0.04068949],\n        [ 0.72156372, -0.06548857, -0.28354471, -0.33169843, -0.55661568,\n          0.73538544, -1.14811836,  0.60550265,  0.31259001],\n        [-0.50434412,  0.2133543 ,  0.14732113, -0.14226134, -0.25425923,\n         -0.7925779 ,  0.6472886 , -0.64083973,  0.63906918]]),\n array([[-0.83002351,  0.21491586,  0.18549303,  1.67385497,  2.61070168,\n         -1.19731444,  1.39413292, -0.96968216,  0.02791928],\n        [ 0.72799706, -0.05182624, -0.27362691, -0.32888128, -0.55307814,\n          0.71184445, -1.09006629,  0.54320281,  0.31834034],\n        [-0.55110046,  0.2074339 ,  0.31130349, -0.10643616, -0.18138642,\n         -0.87313606,  0.70891901, -0.67236975,  0.51726693]]),\n array([[-0.53793096,  0.20762896,  0.32927903, -0.09246677, -0.16330304,\n         -0.91478145,  0.74765988, -0.69908797,  0.16065917],\n        [ 0.68706753, -0.01527389, -0.26272397, -0.32651174, -0.55409556,\n          0.643504  , -1.01675942,  0.4775848 ,  0.28554236],\n        [-0.76684529,  0.21936046,  0.19069755,  1.67605268,  2.59838698,\n         -1.19201772,  1.41645831, -0.97196431, -0.6231677 ]]),\n array([[ 0.73984533, -0.02175058, -0.25285999, -0.32536011, -0.55376708,\n          0.65961288, -0.95758111,  0.41989066, -0.15344911],\n        [-0.53839182,  0.2180355 ,  0.29054905, -0.1238859 , -0.20245858,\n         -0.93841298,  0.73810981, -0.69319345, -0.63743964],\n        [-0.87400565,  0.24977206,  0.29633011,  1.57128605,  2.36731042,\n         -1.21160166,  1.43347462, -0.97356574, -1.44414676]])]</div>"]}}],"execution_count":26},{"cell_type":"code","source":["\n###############################################################################\n########################### NUEVA VISUALIZACION  ##############################\n###############################################################################\n\n#funciones_pyspark.gapminder_plot_bokeh(datos_e, datos_pca, year_i, X_data_df, grad_per,\n#                         etiquetas_glo, periodos_incluir, k, imp_periods_var,\n#                         centroids_ite, scaler_es,\n#                         title = 'Gapminder data',\n#                         xlabel='Componente principal 1',\n#                         ylabel='Componente principal 2')\n\n#    \n#from bokeh.plotting import output_file, save\n#output_file(\"test.html\")\n#save(layout)\n#\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":27},{"cell_type":"code","source":["df1= pd.DataFrame(datos_e)\ndf1.to_csv(\"/dbfs/mnt/mountblob/logs/datos_e.csv\",header=True,index= False)\n\ndf2= pd.DataFrame(datos_pca)\ndf2.to_csv('/dbfs/mnt/mountblob/logs/datos_pca.csv',header=True,index= False)\n\ndf3= pd.DataFrame(X_data_df)\ndf3.to_csv('/dbfs/mnt/mountblob/logs/X_data_df.csv',header=True,index= False)\n\ndf4= pd.DataFrame(grad_per)\ndf4.to_csv('/dbfs/mnt/mountblob/logs/grad_per.csv',header=True,index= False)\n\ndf5= pd.DataFrame(etiquetas_glo)\ndf5.to_csv('/dbfs/mnt/mountblob/logs/etiquetas_glo.csv',header=True,index= False)\n\ndf6= pd.DataFrame(imp_periods_var)\ndf6.to_csv('/dbfs/mnt/mountblob/logs/imp_periods_var.csv',header=True,index= False)\n\n#Los siquientes parámetros son números sin estructura de dataframe\n\ndsimple = pd.DataFrame(columns=('year_i', 'k', 'periodos_incluir', 'scaler_es','dim_centroids_ite'))\n\ndimension = np.array(centroids_ite).shape\nlargo = dimension[2]*dimension[1]\n\ndsimple.loc[len(dsimple)] = [ year_i, k, periodos_incluir,scaler_es,dimension]\ndf7= pd.DataFrame(dsimple)\ndf7.to_csv('/dbfs/mnt/mountblob/logs/yeari_k_periods_scaler_es_dimcentroi.csv',header=True,index= False)\n\ncentros = np.array(centroids_ite).reshape(largo,-1)\ndf8= pd.DataFrame(centros)\ndf8.to_csv('/dbfs/mnt/mountblob/logs/centroids_ite.csv',header=True,index= False)\n\ndatos = pd.DataFrame(datos_pca, columns=['component_1', 'component_2'])\ndatos = pd.concat([datos_e, datos], axis=1, ignore_index=True)\nfrom tabulate import tabulate\nprint(tabulate(datos, headers='keys', tablefmt=\"psql\"))\ndatos.to_csv('/dbfs/mnt/mountblob/logs/datos.csv', header = True, index= False)"],"metadata":{"scrolled":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+--------------------------------+------+-------------+--------------+-------------+--------------+-------------+--------------+-------------+-------------+-------------+-------------+--------------+\n      | 0                              |    1 |           2 |            3 |           4 |            5 |           6 |            7 |           8 |           9 |          10 |          11 |           12 |\n------+--------------------------------+------+-------------+--------------+-------------+--------------+-------------+--------------+-------------+-------------+-------------+-------------+--------------|\n    0 | Albania                        | 1980 |  0.296492   | -0.561724    | -0.104627   | -0.371121    | -0.525008   | -0.0900206   |  0.567004   |  0.126375   | -0.0671372  | -0.259132   | -0.656978    |\n    1 | Albania                        | 1981 |  0.251781   | -0.56004     | -0.0938847  | -0.370626    | -0.51966    | -0.158878    |  0.57735    |  0.039654   | -0.119946   | -0.163603   | -0.687113    |\n    2 | Albania                        | 1982 |  0.350144   | -0.558638    | -0.0814462  | -0.370347    | -0.518323   | -0.217142    |  0.587696   | -0.0380962  | -0.134733   | -0.134731   | -0.695263    |\n    3 | Albania                        | 1983 |  0.359086   | -0.557235    | -0.0701385  | -0.370239    | -0.520328   | -0.270109    |  0.598042   | -0.111361   | -0.124171   | -0.0768866  | -0.714916    |\n    4 | Albania                        | 1984 |  0.341202   | -0.555552    | -0.0588308  | -0.370363    | -0.525008   | -0.323076    |  0.618734   | -0.178645   | -0.094598   | -0.00776239 | -0.738705    |\n    5 | Albania                        | 1985 |  0.305434   | -0.553588    | -0.0475231  | -0.370193    | -0.525677   | -0.36545     |  0.639426   | -0.238453   | -0.0629125  |  0.0619237  | -0.762046    |\n    6 | Albania                        | 1986 |  0.189186   | -0.551624    | -0.0305615  | -0.369651    | -0.520328   | -0.402527    |  0.660118   | -0.29228    |  0.0194698  |  0.160897   | -0.795064    |\n    7 | Albania                        | 1987 |  0.251781   | -0.549379    | -0.0135999  | -0.369729    | -0.52434    | -0.439604    |  0.660118   | -0.338631   |  0.0511553  |  0.174407   | -0.797642    |\n    8 | Albania                        | 1988 |  0.153418   | -0.547135    |  0.00336161 | -0.369868    | -0.529019   | -0.466088    |  0.680809   | -0.377506   |  0.0110203  |  0.253015   | -0.821637    |\n    9 | Albania                        | 1989 |  0.868785   | -0.545732    |  0.0146693  | -0.368894    | -0.51966    | -0.497868    |  0.711847   | -0.411895   | -0.094598   |  0.0222148  | -0.733352    |\n   10 | Albania                        | 1990 |  0.0729393  | -0.54489     |  0.0203232  | -0.369945    | -0.535704   | -0.534945    |  0.732539   | -0.438809   | -0.250913   |  0.369568   | -0.852536    |\n   11 | Albania                        | 1991 | -2.07584    | -0.54489     |  0.0203232  | -0.372868    | -0.573809   | -0.497868    |  0.732539   | -0.464227   | -6.76545    |  1.28372    | -1.03429     |\n   12 | Albania                        | 1992 | -2.07853    | -0.546013    |  0.00901546 | -0.373379    | -0.579826   | -0.466088    |  0.732539   | -0.48516    | -2.51748    |  1.21552    | -1.11617     |\n   13 | Albania                        | 1993 | -2.0821     | -0.547415    | -0.00229224 | -0.37276     | -0.571135   | -0.444901    |  0.732539   | -0.506093   |  0.898214   |  1.16976    | -1.18372     |\n   14 | Albania                        | 1994 | -2.08568    | -0.548818    | -0.00794609 | -0.372157    | -0.562445   | -0.423714    |  0.742885   | -0.52553    |  0.591921   |  1.18079    | -1.18381     |\n   15 | Albania                        | 1995 | -2.08926    | -0.54966     | -0.0192538  | -0.371136    | -0.548406   | -0.407824    |  0.753231   | -0.544968   |  1.70514    |  1.17559    | -1.21028     |\n   16 | Albania                        | 1996 | -2.09283    | -0.550221    | -0.0192538  | -0.370347    | -0.536373   | -0.460791    |  0.773923   | -0.5659     |  0.957361   |  1.2342     | -1.20988     |\n   17 | Albania                        | 1997 | -2.09552    | -0.550221    | -0.0192538  | -0.371384    | -0.549743   | -0.513758    |  0.587696   | -0.586833   | -3.00544    |  1.23609    | -1.12016     |\n   18 | Albania                        | 1998 | -2.09909    | -0.54994     | -0.0192538  | -0.37061     | -0.538378   | -0.556132    |  0.773923   | -0.607766   |  1.83188    |  1.28504    | -1.24487     |\n   19 | Albania                        | 1999 | -2.10267    | -0.549379    | -0.0135999  | -0.369373    | -0.520328   | -0.598506    |  0.784269   | -0.627204   |  1.31646    |  1.33387    | -1.24441     |\n   20 | Albania                        | 2000 | -2.10625    | -0.549379    | -0.0135999  | -0.368677    | -0.509632   | -0.651473    |  0.784269   | -0.648136   |  0.767248   |  1.38013    | -1.24421     |\n   21 | Albania                        | 2001 | -2.3754     | -0.549379    | -0.0135999  | -0.36778     | -0.495594   | -0.699144    |  0.794614   | -0.666079   |  0.794708   |  1.52486    | -1.29168     |\n   22 | Albania                        | 2002 | -1.8049     | -0.549379    | -0.0135999  | -0.36727     | -0.48824    | -0.757408    |  0.794614   | -0.685516   |  0.032144   |  1.34902    | -1.20821     |\n   23 | Albania                        | 2003 | -1.87107    | -0.54966     | -0.0135999  | -0.366558    | -0.476875   | -0.820968    |  0.80496    | -0.701963   |  0.613045   |  1.41184    | -1.23911     |\n   24 | Albania                        | 2004 | -1.91042    | -0.54994     | -0.0192538  | -0.365785    | -0.46551    | -0.895122    |  0.815306   | -0.716915   |  0.600371   |  1.47556    | -1.25649     |\n   25 | Albania                        | 2005 | -1.99447    | -0.550501    | -0.0249077  | -0.364996    | -0.452809   | -0.974573    |  0.835998   | -0.731867   |  0.507426   |  1.56541    | -1.28085     |\n   26 | Albania                        | 2006 | -2.10088    | -0.551343    | -0.0305615  | -0.364223    | -0.440107   | -1.04343     |  0.867036   | -0.746819   |  0.558123   |  1.66174    | -1.31169     |\n   27 | Albania                        | 2007 | -2.21266    | -0.552185    | -0.0362154  | -0.363295    | -0.424731   | -1.11229     |  0.887728   | -0.758781   |  0.575022   |  1.75584    | -1.34042     |\n   28 | Albania                        | 2008 | -2.2225     | -0.553026    | -0.0418692  | -0.362677    | -0.413366   | -1.17585     |  0.908419   | -0.769247   |  0.868641   |  1.80141    | -1.35938     |\n   29 | Albania                        | 2009 | -2.13933    | -0.553868    | -0.0475231  | -0.362058    | -0.403339   | -1.23411     |  0.939457   | -0.779714   |  0.032144   |  1.82785    | -1.34576     |\n   30 | Albania                        | 2010 | -1.98016    | -0.554429    | -0.0531769  | -0.361439    | -0.392643   | -1.27119     |  0.980841   | -0.788685   |  0.0490429  |  1.80709    | -1.33626     |\n   31 | Algeria                        | 1980 |  1.17282    | -0.0954388   | -0.61223    | -0.271585    | -0.424063   |  1.43014     | -0.488279   |  1.176      | -0.234014   | -2.18174    |  0.363917    |\n   32 | Algeria                        | 1981 |  1.22647    | -0.0786054   | -0.610816   | -0.268338    | -0.424063   |  1.40895     | -0.353782   |  0.951724   | -0.094598   | -2.03688    |  0.311683    |\n   33 | Algeria                        | 1982 |  1.2533     | -0.0589664   | -0.60929    | -0.261224    | -0.416709   |  1.37717     | -0.250323   |  0.712492   |  0.722888   | -1.88928    |  0.247776    |\n   34 | Algeria                        | 1983 |  1.2533     | -0.042133    | -0.607763   | -0.254728    | -0.411361   |  1.34009     | -0.115826   |  0.473261   |  0.452505   | -1.7011     |  0.192575    |\n   35 | Algeria                        | 1984 |  1.22647    | -0.0224941   | -0.60618    | -0.247769    | -0.405344   |  1.29242     |  0.00832494 |  0.251972   |  0.515876   | -1.51371    |  0.134457    |\n   36 | Algeria                        | 1985 |  1.16387    | -0.00285509  | -0.604597   | -0.24282     | -0.404007   |  1.22886     |  0.12213    |  0.0650723  |  0.433494   | -1.32452    |  0.0806985   |\n   37 | Algeria                        | 1986 |  1.10128    |  0.0139783   | -0.602958   | -0.242356    | -0.410024   |  1.1759      |  0.194551   | -0.0739809  | -0.857585   | -1.1663     |  0.0622884   |\n   38 | Algeria                        | 1987 |  1.02974    |  0.0336173   | -0.601601   | -0.243284    | -0.419383   |  1.10704     |  0.266973   | -0.171169   | -0.781751   | -1.03556    |  0.0268078   |\n   39 | Algeria                        | 1988 |  0.949264   |  0.0532562   | -0.599904   | -0.244676    | -0.428742   |  1.02759     |  0.329048   | -0.236957   | -1.10008    | -0.909026   |  0.00461365  |\n   40 | Algeria                        | 1989 |  0.850901   |  0.0728952   | -0.598208   | -0.238644    | -0.424731   |  0.937544    |  0.380778   | -0.277328   |  0.0617171  | -0.799672   | -0.0369622   |\n   41 | Algeria                        | 1990 |  0.752538   |  0.0897286   | -0.596512   | -0.237562    | -0.428742   |  0.836906    |  0.432507   | -0.304241   | -0.967005   | -0.665381   | -0.0411945   |\n   42 | Algeria                        | 1991 |  0.654175   |  0.109368    | -0.595381   | -0.239263    | -0.437433   |  0.736268    |  0.473891   | -0.325174   | -0.888848   | -0.555904   | -0.0622838   |\n   43 | Algeria                        | 1992 |  0.54687    |  0.126201    | -0.593685   | -0.236788    | -0.43877    |  0.630334    |  0.504929   | -0.341621   | -0.312172   | -0.450276   | -0.0915282   |\n   44 | Algeria                        | 1993 |  0.430623   |  0.143034    | -0.591989   | -0.239727    | -0.448129   |  0.513806    |  0.535967   | -0.356573   | -1.13177    | -0.32196    | -0.100031    |\n   45 | Algeria                        | 1994 |  0.296492   |  0.159868    | -0.590858   | -0.240964    | -0.454814   |  0.381388    |  0.546312   | -0.37302    | -0.871738   | -0.201553   | -0.128674    |\n   46 | Algeria                        | 1995 |  0.153418   |  0.173896    | -0.589728   | -0.235706    | -0.450803   |  0.243673    |  0.567004   | -0.389467   |  0.118751   | -0.075395   | -0.172553    |\n   47 | Algeria                        | 1996 |  0.0192868  |  0.187923    | -0.588597   | -0.229829    | -0.445455   |  0.111255    |  0.618734   | -0.404419   |  0.125088   |  0.0722747  | -0.200582    |\n   48 | Algeria                        | 1997 | -0.105902   |  0.201951    | -0.587466   | -0.228128    | -0.446792   | -0.0370533   |  0.639426   | -0.416381   | -0.445251   |  0.213098   | -0.215307    |\n   49 | Algeria                        | 1998 | -0.204265   |  0.213173    | -0.586335   | -0.22055     | -0.43877    | -0.185362    |  0.649772   | -0.426847   |  0.401808   |  0.323194   | -0.249351    |\n   50 | Algeria                        | 1999 | -0.275802   |  0.227201    | -0.585204   | -0.21591     | -0.434759   | -0.33367     |  0.691155   | -0.434323   |  0.00257088 |  0.450566   | -0.26024     |\n   51 | Algeria                        | 2000 | -0.329455   |  0.238424    | -0.584074   | -0.209724    | -0.429411   | -0.476681    |  0.732539   | -0.443294   | -0.143182   |  0.566205   | -0.274397    |\n   52 | Algeria                        | 2001 | -0.374165   |  0.249646    | -0.582943   | -0.203538    | -0.4254     | -0.62499     |  0.753231   | -0.455256   | -0.107272   |  0.669862   | -0.288729    |\n   53 | Algeria                        | 2002 | -0.400991   |  0.260868    | -0.582378   | -0.194258    | -0.415372   | -0.757408    |  0.784269   | -0.471703   |  0.199021   |  0.764938   | -0.304968    |\n   54 | Algeria                        | 2003 | -0.400991   |  0.27209     | -0.581247   | -0.18034     | -0.400665   | -0.873936    |  0.794614   | -0.491141   |  0.826394   |  0.83302    | -0.316902    |\n   55 | Algeria                        | 2004 | -0.365223   |  0.283313    | -0.580116   | -0.172607    | -0.392643   | -0.97987     |  0.85669    | -0.512073   |  0.482078   |  0.915041   | -0.316462    |\n   56 | Algeria                        | 2005 | -0.302628   |  0.29734     | -0.578985   | -0.160235    | -0.380609   | -1.06991     |  0.887728   | -0.535997   |  0.475741   |  0.965239   | -0.308416    |\n   57 | Algeria                        | 2006 | -0.231092   |  0.311368    | -0.577854   | -0.155595    | -0.379941   | -1.13877     |  0.908419   | -0.556929   | -0.297385   |  1.00075    | -0.285138    |\n   58 | Algeria                        | 2007 | -0.168497   |  0.325396    | -0.576724   | -0.147862    | -0.374593   | -1.18644     |  0.939457   | -0.577862   |  0.0617171  |  1.02151    | -0.281715    |\n   59 | Algeria                        | 2008 | -0.0880183  |  0.342229    | -0.575593   | -0.143223    | -0.372587   | -1.21822     |  0.960149   | -0.5973     | -0.234014   |  1.03013    | -0.260067    |\n   60 | Algeria                        | 2009 |  0.00140259 |  0.359063    | -0.573897   | -0.138583    | -0.372587   | -1.23411     |  0.980841   | -0.613747   | -0.30161    |  1.0229     | -0.239138    |\n   61 | Algeria                        | 2010 |  0.0908235  |  0.375896    | -0.572201   | -0.13085     | -0.367908   | -1.22882     |  1.00153    | -0.628699   |  0.0934026  |  1.00152    | -0.222699    |\n   62 | Antigua and Barbuda            | 1980 | -1.64126    | -0.634854    |  0.286054   | -0.379234    | -0.307742   | -0.439604    |  0.391124   | -0.393953   |  1.00595    |  0.931115   | -1.09898     |\n   63 | Antigua and Barbuda            | 1981 | -1.99537    | -0.634862    |  0.2804     | -0.379211    | -0.291697   | -0.556132    |  0.442853   | -0.419371   |  0.488415   |  1.16914    | -1.16341     |\n   64 | Antigua and Barbuda            | 1982 | -2.29582    | -0.634882    |  0.274747   | -0.379211    | -0.289023   | -0.64088     |  0.484237   | -0.443294   | -0.591427   |  1.36931    | -1.2051      |\n   65 | Antigua and Barbuda            | 1983 | -2.53815    | -0.634904    |  0.263439   | -0.379177    | -0.264288   | -0.70444     |  0.546312   | -0.467218   |  0.701764   |  1.52013    | -1.28408     |\n   66 | Antigua and Barbuda            | 1984 | -2.68122    | -0.634929    |  0.252131   | -0.37911     | -0.217492   | -0.768001    |  0.567004   | -0.489645   |  0.839068   |  1.63723    | -1.32203     |\n   67 | Antigua and Barbuda            | 1985 | -2.73488    | -0.634955    |  0.240823   | -0.379053    | -0.176713   | -0.826265    |  0.587696   | -0.510578   |  0.976372   |  1.71393    | -1.34667     |\n   68 | Antigua and Barbuda            | 1986 | -2.78853    | -0.634983    |  0.223862   | -0.378963    | -0.113204   | -0.847452    |  0.618734   | -0.541977   |  1.20662    |  1.78878    | -1.37422     |\n   69 | Antigua and Barbuda            | 1987 | -2.79747    | -0.635011    |  0.212554   | -0.378904    | -0.0677456  | -0.858045    |  0.649772   | -0.570386   |  1.34815    |  1.83559    | -1.39158     |\n   70 | Antigua and Barbuda            | 1988 | -2.58286    | -0.63503     |  0.201246   | -0.378855    | -0.0296404  | -0.842155    |  0.670463   | -0.5973     |  1.1517     |  1.7793     | -1.36732     |\n   71 | Antigua and Barbuda            | 1989 | -2.1134     | -0.635044    |  0.195593   | -0.378804    |  0.00913328 | -0.752111    |  0.691155   | -0.622718   |  0.758798   |  1.59244    | -1.29646     |\n   72 | Antigua and Barbuda            | 1990 | -1.44364    | -0.635042    |  0.201246   | -0.378773    |  0.0291886  | -0.598506    |  0.722193   | -0.646641   |  0.0258069  |  1.30175    | -1.18566     |\n   73 | Antigua and Barbuda            | 1991 | -0.721118   | -0.635025    |  0.2069     | -0.37875     |  0.0358738  | -0.614396    |  0.742885   | -0.669069   | -0.145295   |  1.04969    | -1.09153     |\n   74 | Antigua and Barbuda            | 1992 | -0.061192   | -0.634994    |  0.223862   | -0.378736    |  0.0358738  | -0.603803    |  0.753231   | -0.690002   | -0.443138   |  0.80632    | -0.998388    |\n   75 | Antigua and Barbuda            | 1993 |  0.412739   | -0.634952    |  0.240823   | -0.378679    |  0.0559291  | -0.577319    |  0.763577   | -0.710935   |  0.479966   |  0.61914    | -0.952203    |\n   76 | Antigua and Barbuda            | 1994 |  0.707828   | -0.634901    |  0.263439   | -0.3786      |  0.0826696  | -0.572022    |  0.773923   | -0.728877   |  0.667966   |  0.524338   | -0.918264    |\n   77 | Antigua and Barbuda            | 1995 |  0.797249   | -0.634848    |  0.286054   | -0.378654    |  0.0291886  | -0.587913    |  0.784269   | -0.745324   | -1.54579    |  0.523383   | -0.869275    |\n   78 | Antigua and Barbuda            | 1996 |  0.868785   | -0.634792    |  0.314323   | -0.378577    |  0.0559291  | -0.662067    |  0.784269   | -0.761771   |  0.739787   |  0.519256   | -0.909808    |\n   79 | Antigua and Barbuda            | 1997 |  0.922438   | -0.634733    |  0.342593   | -0.378507    |  0.0759845  | -0.720331    |  0.825652   | -0.776723   |  0.406033   |  0.566578   | -0.909019    |\n   80 | Antigua and Barbuda            | 1998 |  0.859843   | -0.634671    |  0.365208   | -0.378444    |  0.0893548  | -0.757408    |  0.846344   | -0.79018    |  0.279291   |  0.633772   | -0.923142    |\n   81 | Antigua and Barbuda            | 1999 |  0.654175   | -0.634618    |  0.393477   | -0.378391    |  0.102725   | -0.773298    |  0.835998   | -0.803637   |  0.21592    |  0.733955   | -0.95126     |\n   82 | Antigua and Barbuda            | 2000 |  0.359086   | -0.634567    |  0.416093   | -0.378297    |  0.136151   | -0.789188    |  0.815306   | -0.814103   | -0.343857   |  0.876671   | -0.981242    |\n   83 | Antigua and Barbuda            | 2001 |  0.0282289  | -0.634525    |  0.433054   | -0.378371    |  0.0826696  | -0.815672    |  0.85669    | -0.824569   | -0.195992   |  1.0229     | -1.03848     |\n   84 | Antigua and Barbuda            | 2002 | -0.275802   | -0.634492    |  0.450016   | -0.378355    |  0.0759845  | -0.847452    |  0.877382   | -0.833541   | -0.128396   |  1.16953    | -1.08834     |\n   85 | Antigua and Barbuda            | 2003 | -0.48147    | -0.634464    |  0.461324   | -0.378266    |  0.116095   | -0.873936    |  0.898074   | -0.841017   |  0.441943   |  1.28359    | -1.1341      |\n   86 | Antigua and Barbuda            | 2004 | -0.553007   | -0.634436    |  0.478285   | -0.378173    |  0.149521   | -0.884529    |  0.918765   | -0.848493   |  0.862304   |  1.33837    | -1.15648     |\n   87 | Antigua and Barbuda            | 2005 | -0.535123   | -0.634408    |  0.489593   | -0.378065    |  0.196317   | -0.879232    |  0.939457   | -0.855969   |  0.319426   |  1.36806    | -1.14801     |\n   88 | Antigua and Barbuda            | 2006 | -0.490412   | -0.634379    |  0.500901   | -0.377848    |  0.289908   | -0.921606    |  0.949803   | -0.861949   |  2.02199    |  1.38965    | -1.1802      |\n   89 | Antigua and Barbuda            | 2007 | -0.472528   | -0.634349    |  0.517862   | -0.377663    |  0.37013    | -0.969277    |  0.991187   | -0.866435   |  0.820057   |  1.47384    | -1.16697     |\n   90 | Antigua and Barbuda            | 2008 | -0.472528   | -0.634318    |  0.52917    | -0.377663    |  0.35676    | -1.02224     |  1.01188    | -0.872416   | -0.348082   |  1.52311    | -1.15371     |\n   91 | Antigua and Barbuda            | 2009 | -0.472528   | -0.634287    |  0.546131   | -0.377925    |  0.223057   | -1.08051     |  1.04292    | -0.878397   | -2.92094    |  1.5558     | -1.11453     |\n   92 | Antigua and Barbuda            | 2010 | -0.508297   | -0.634256    |  0.557439   | -0.378065    |  0.149521   | -1.14407     |  1.03257    | -0.882882   | -2.26189    |  1.56208    | -1.13492     |\n   93 | Argentina                      | 1980 | -0.186381   |  0.151451    | -0.599904   | -0.0303253   | -0.127912   | -0.487275    |  0.308356   | -0.386477   | -0.33752    |  0.454024   | -0.146556    |\n   94 | Argentina                      | 1981 | -0.159555   |  0.162673    | -0.599339   | -0.0504303   | -0.166017   | -0.434308    |  0.34974    | -0.437314   | -1.82885    |  0.461844   | -0.13033     |\n   95 | Argentina                      | 1982 | -0.132729   |  0.176701    | -0.598208   | -0.0658957   | -0.198106   | -0.402527    |  0.380778   | -0.480674   | -1.30076    |  0.447381   | -0.145173    |\n   96 | Argentina                      | 1983 | -0.123787   |  0.190729    | -0.597078   | -0.0535234   | -0.188078   | -0.386637    |  0.391124   | -0.518054   |  0.239156   |  0.444688   | -0.162967    |\n   97 | Argentina                      | 1984 | -0.132729   |  0.201951    | -0.596512   | -0.0473373   | -0.184735   | -0.376044    |  0.422162   | -0.547958   | -0.189654   |  0.480183   | -0.154622    |\n   98 | Argentina                      | 1985 | -0.150613   |  0.215979    | -0.595381   | -0.0720819   | -0.228189   | -0.354857    |  0.463545   | -0.571881   | -2.12881    |  0.511975   | -0.133729    |\n   99 | Argentina                      | 1986 | -0.168497   |  0.230007    | -0.594251   | -0.0473373   | -0.20078    | -0.354857    |  0.494583   | -0.588328   |  0.917226   |  0.516154   | -0.175939    |\n  100 | Argentina                      | 1987 | -0.186381   |  0.241229    | -0.593685   | -0.038058    | -0.194763   | -0.33367     |  0.515275   | -0.5973     | -0.0776991  |  0.546565   | -0.14957     |\n  101 | Argentina                      | 1988 | -0.204265   |  0.255257    | -0.592554   | -0.0473373   | -0.213481   | -0.31778     |  0.525621   | -0.601785   | -1.04094    |  0.558601   | -0.129741    |\n  102 | Argentina                      | 1989 | -0.231092   |  0.269285    | -0.591424   | -0.0720819   | -0.253592   | -0.312483    |  0.535967   | -0.60328    | -2.14359    |  0.567449   | -0.117367    |\n  103 | Argentina                      | 1990 | -0.257918   |  0.280507    | -0.590293   | -0.0798146   | -0.268968   | -0.328373    |  0.546312   | -0.606271   | -1.0515     |  0.569563   | -0.140347    |\n  104 | Argentina                      | 1991 | -0.275802   |  0.294535    | -0.589728   | -0.0411511   | -0.224846   | -0.33367     |  0.567004   | -0.613747   |  1.62064    |  0.582911   | -0.165072    |\n  105 | Argentina                      | 1992 | -0.302628   |  0.308563    | -0.588597   | -0.000941097 | -0.178719   | -0.354857    |  0.587696   | -0.624213   |  1.45165    |  0.649137   | -0.140233    |\n  106 | Argentina                      | 1993 | -0.329455   |  0.319785    | -0.587466   |  0.022257    | -0.157326   | -0.39723     |  0.608388   | -0.639165   |  0.615157   |  0.722052   | -0.117531    |\n  107 | Argentina                      | 1994 | -0.374165   |  0.333813    | -0.586901   |  0.0454551   | -0.134597   | -0.434308    |  0.639426   | -0.657107   |  0.632056   |  0.79425    | -0.112591    |\n  108 | Argentina                      | 1995 | -0.409934   |  0.345035    | -0.58577    |  0.0330828   | -0.155989   | -0.466088    |  0.649772   | -0.673555   | -1.23105    |  0.850511   | -0.0896846   |\n  109 | Argentina                      | 1996 | -0.454644   |  0.356257    | -0.585204   |  0.0562809   | -0.133928   | -0.492572    |  0.670463   | -0.690002   |  0.556011   |  0.887448   | -0.116442    |\n  110 | Argentina                      | 1997 | -0.499354   |  0.36748     | -0.584074   |  0.0918513   | -0.0978287  | -0.513758    |  0.691155   | -0.706449   |  1.101      |  0.948002   | -0.113094    |\n  111 | Argentina                      | 1998 | -0.526181   |  0.378702    | -0.583508   |  0.108863    | -0.0824529  | -0.534945    |  0.711847   | -0.721401   |  0.182122   |  1.00835    | -0.0903813   |\n  112 | Argentina                      | 1999 | -0.535123   |  0.389924    | -0.582378   |  0.0933978   | -0.108525   | -0.556132    |  0.732539   | -0.734858   | -1.37469    |  1.04568    | -0.070927    |\n  113 | Argentina                      | 2000 | -0.544065   |  0.403952    | -0.581812   |  0.0887582   | -0.119221   | -0.577319    |  0.763577   | -0.746819   | -0.83118    |  1.0666     | -0.0831629   |\n  114 | Argentina                      | 2001 | -0.544065   |  0.415174    | -0.580681   |  0.0686532   | -0.148636   | -0.603803    |  0.784269   | -0.757286   | -1.6155     |  1.08827    | -0.0790322   |\n  115 | Argentina                      | 2002 | -0.544065   |  0.426396    | -0.580116   |  0.0191639   | -0.210139   | -0.62499     |  0.794614   | -0.766257   | -3.00544    |  1.0906     | -0.0776956   |\n  116 | Argentina                      | 2003 | -0.553007   |  0.437619    | -0.578985   |  0.0547343   | -0.175376   | -0.646176    |  0.80496    | -0.773733   |  1.18972    |  1.07738    | -0.132721    |\n  117 | Argentina                      | 2004 | -0.561949   |  0.448841    | -0.577854   |  0.0933978   | -0.137271   | -0.667363    |  0.835998   | -0.781209   |  1.21507    |  1.13346    | -0.112694    |\n\n*** WARNING: skipped 643977 bytes of output ***\n\n 3229 | Vanuatu                        | 1985 |  0.50216    | -0.633266    | -0.597643   | -0.379305    | -0.486903   |  1.0064      | -0.5607     | -0.325174   | -0.441026   | -1.22655    | -0.553814    |\n 3230 | Vanuatu                        | 1986 |  0.511102   | -0.633182    | -0.596512   | -0.379307    | -0.491582   |  0.979917    | -0.550354   | -0.37302    | -1.10431    | -1.18527    | -0.554845    |\n 3231 | Vanuatu                        | 1987 |  0.511102   | -0.633097    | -0.594816   | -0.379322    | -0.500273   |  0.958731    | -0.61243    | -0.414886   | -0.585723   | -1.19525    | -0.566164    |\n 3232 | Vanuatu                        | 1988 |  0.564754   | -0.633013    | -0.593685   | -0.37933     | -0.506958   |  0.953434    | -0.529663   | -0.45077    | -0.55615    | -1.16469    | -0.579707    |\n 3233 | Vanuatu                        | 1989 |  0.672059   | -0.632901    | -0.591989   | -0.379322    | -0.508295   |  0.958731    | -0.529663   | -0.480674   |  0.0448182  | -1.20505    | -0.581769    |\n 3234 | Vanuatu                        | 1990 |  0.806191   | -0.632789    | -0.590293   | -0.379262    | -0.494925   |  0.969324    | -0.508971   | -0.506093   |  0.329988   | -1.24133    | -0.576087    |\n 3235 | Vanuatu                        | 1991 |  0.958206   | -0.632677    | -0.588031   | -0.379243    | -0.494256   |  0.916357    | -0.498625   | -0.527025   |  1.87413    | -1.28423    | -0.594152    |\n 3236 | Vanuatu                        | 1992 |  1.07445    | -0.632564    | -0.586335   | -0.379228    | -0.494925   |  0.873983    | -0.488279   | -0.546463   | -0.833081   | -1.25993    | -0.537992    |\n 3237 | Vanuatu                        | 1993 |  1.05657    | -0.632424    | -0.584074   | -0.379223    | -0.498268   |  0.831609    | -0.488279   | -0.561415   |  0.270841   | -1.24337    | -0.567621    |\n 3238 | Vanuatu                        | 1994 |  0.886669   | -0.632312    | -0.581812   | -0.379167    | -0.48824    |  0.789235    | -0.477933   | -0.573376   | -0.14107    | -1.13777    | -0.591607    |\n 3239 | Vanuatu                        | 1995 |  0.627349   | -0.6322      | -0.580116   | -0.37916     | -0.490245   |  0.741565    | -0.467587   | -0.582348   |  0.310976   | -1.01245    | -0.643527    |\n 3240 | Vanuatu                        | 1996 |  0.341202   | -0.632087    | -0.57842    | -0.379144    | -0.490245   |  0.699191    | -0.467587   | -0.589824   |  0.836956   | -0.884507   | -0.698196    |\n 3241 | Vanuatu                        | 1997 |  0.108708   | -0.632003    | -0.576724   | -0.37911     | -0.484897   |  0.651521    | -0.581392   | -0.52553    |  0.363786   | -0.84024    | -0.694932    |\n 3242 | Vanuatu                        | 1998 |  0.0192868  | -0.631919    | -0.575593   | -0.379078    | -0.480218   |  0.593257    | -0.457241   | -0.598795   |  0.239156   | -0.688766   | -0.744992    |\n 3243 | Vanuatu                        | 1999 |  0.0908235  | -0.631835    | -0.573897   | -0.379076    | -0.482892   |  0.540289    | -0.508971   | -0.60328    | -1.33456    | -0.692396   | -0.704293    |\n 3244 | Vanuatu                        | 2000 |  0.278607   | -0.631723    | -0.572201   | -0.37903     | -0.476207   |  0.492619    | -0.457241   | -0.607766   | -0.0924856  | -0.734193   | -0.713934    |\n 3245 | Vanuatu                        | 2001 |  0.484275   | -0.63161     | -0.570504   | -0.379059    | -0.486903   |  0.429058    | -0.457241   | -0.610756   | -1.22471    | -0.772579   | -0.670882    |\n 3246 | Vanuatu                        | 2002 |  0.645233   | -0.63147     | -0.568243   | -0.379099    | -0.500273   |  0.360201    | -0.467587   | -0.613747   | -2.16894    | -0.799047   | -0.636334    |\n 3247 | Vanuatu                        | 2003 |  0.743596   | -0.63133     | -0.565981   | -0.379067    | -0.497599   |  0.291343    | -0.467587   | -0.615242   |  0.0384811  | -0.834984   | -0.669609    |\n 3248 | Vanuatu                        | 2004 |  0.76148    | -0.63119     | -0.56372    | -0.379036    | -0.494925   |  0.23308     | -0.477933   | -0.613747   |  0.52855    | -0.826058   | -0.679397    |\n 3249 | Vanuatu                        | 2005 |  0.725712   | -0.631049    | -0.560893   | -0.378993    | -0.490245   |  0.185409    | -0.467587   | -0.612252   |  0.803158   | -0.787901   | -0.694719    |\n 3250 | Vanuatu                        | 2006 |  0.681001   | -0.630881    | -0.558631   | -0.378921    | -0.480218   |  0.100661    | -0.457241   | -0.610756   |  1.20662    | -0.72925    | -0.71718     |\n 3251 | Vanuatu                        | 2007 |  0.654175   | -0.630741    | -0.55637    | -0.378874    | -0.475538   |  0.0635844   | -0.446895   | -0.607766   |  0.498977   | -0.686497   | -0.711993    |\n 3252 | Vanuatu                        | 2008 |  0.627349   | -0.6306      | -0.553543   | -0.378812    | -0.468185   |  0.0582877   | -0.426203   | -0.606271   |  0.758798   | -0.665416   | -0.723424    |\n 3253 | Vanuatu                        | 2009 |  0.600523   | -0.630432    | -0.551281   | -0.378776    | -0.466179   |  0.0635844   | -0.415858   | -0.60328    |  0.0870655  | -0.643465   | -0.7149      |\n 3254 | Vanuatu                        | 2010 |  0.573696   | -0.630292    | -0.548454   | -0.378759    | -0.467516   |  0.052991    | -0.395166   | -0.60029    | -0.269924   | -0.615214   | -0.715078    |\n 3255 | Venezuela                      | 1980 |  0.895612   | -0.207661    | -0.559762   | -0.0442442   |  0.276538   |  0.386685    |  0.329048   | -0.376011   | -1.14233    | -0.243731   | -0.183558    |\n 3256 | Venezuela                      | 1981 |  0.868785   | -0.193634    | -0.556935   | -0.0457907   |  0.249798   |  0.323124    |  0.370432   | -0.404419   | -0.731899   | -0.187618   | -0.202769    |\n 3257 | Venezuela                      | 1982 |  0.841959   | -0.182411    | -0.554108   | -0.0535234   |  0.209687   |  0.254266    |  0.391124   | -0.429838   | -1.12543    | -0.135276   | -0.209449    |\n 3258 | Venezuela                      | 1983 |  0.815133   | -0.171189    | -0.551847   | -0.0658957   |  0.149521   |  0.180112    |  0.442853   | -0.453761   | -2.24076    | -0.0661564  | -0.210007    |\n 3259 | Venezuela                      | 1984 |  0.806191   | -0.157161    | -0.54902    | -0.0612561   |  0.142836   |  0.121848    |  0.484237   | -0.474694   | -1.26062    | -0.0215178  | -0.231818    |\n 3260 | Venezuela                      | 1985 |  0.797249   | -0.145939    | -0.546193   | -0.0597096   |  0.12278    |  0.0794746   |  0.515275   | -0.494131   | -0.617197   |  0.00926068 | -0.247791    |\n 3261 | Venezuela                      | 1986 |  0.788306   | -0.131911    | -0.542801   | -0.0396046   |  0.156206   |  0.0476942   |  0.567004   | -0.513569   |  0.249718   |  0.0664914  | -0.258053    |\n 3262 | Venezuela                      | 1987 |  0.770422   | -0.120689    | -0.539974   | -0.0272323   |  0.162891   |  0.0265073   |  0.556658   | -0.534501   |  1.00172    |  0.0848209  | -0.263785    |\n 3263 | Venezuela                      | 1988 |  0.734654   | -0.106661    | -0.537147   | -0.00712725  |  0.189632   |  0.0106172   |  0.587696   | -0.553939   |  0.932012   |  0.146699   | -0.256019    |\n 3264 | Venezuela                      | 1989 |  0.681001   | -0.0926332   | -0.533754   | -0.038058    |  0.0960399  | -0.00527299  |  0.587696   | -0.574872   | -2.0422     |  0.184609   | -0.22034     |\n 3265 | Venezuela                      | 1990 |  0.618407   | -0.0786054   | -0.530927   | -0.0164065   |  0.12278    | -0.0370533   |  0.608388   | -0.592814   |  0.501089   |  0.22311    | -0.262905    |\n 3266 | Venezuela                      | 1991 |  0.555812   | -0.0673831   | -0.527535   |  0.0191639   |  0.182946   | -0.0582402   |  0.598042   | -0.609261   |  1.06087    |  0.286009   | -0.257923    |\n 3267 | Venezuela                      | 1992 |  0.493218   | -0.0533553   | -0.524708   |  0.042362    |  0.209687   | -0.100614    |  0.598042   | -0.621223   |  0.870754   |  0.356154   | -0.246129    |\n 3268 | Venezuela                      | 1993 |  0.439565   | -0.0393274   | -0.521881   |  0.0439085   |  0.196317   | -0.148285    |  0.608388   | -0.628699   | -0.581921   |  0.42464    | -0.222656    |\n 3269 | Venezuela                      | 1994 |  0.385912   | -0.0281052   | -0.519054   |  0.0346293   |  0.156206   | -0.195955    |  0.608388   | -0.636175   | -1.46975    |  0.467514   | -0.215858    |\n 3270 | Venezuela                      | 1995 |  0.350144   | -0.0140774   | -0.515662   |  0.0500947   |  0.169576   | -0.243626    |  0.639426   | -0.645146   | -0.153744   |  0.514014   | -0.236481    |\n 3271 | Venezuela                      | 1996 |  0.305434   | -4.95281e-05 | -0.512835   |  0.0500947   |  0.156206   | -0.296593    |  0.691155   | -0.655612   | -0.67119    |  0.587494   | -0.237043    |\n 3272 | Venezuela                      | 1997 |  0.260723   |  0.0111727   | -0.510008   |  0.0779324   |  0.189632   | -0.344263    |  0.742885   | -0.670564   |  0.748236   |  0.658167   | -0.260633    |\n 3273 | Venezuela                      | 1998 |  0.224955   |  0.0252006   | -0.507181   |  0.0779324   |  0.176261   | -0.391934    |  0.753231   | -0.685516   | -0.555728   |  0.720309   | -0.239951    |\n 3274 | Venezuela                      | 1999 |  0.189186   |  0.0364228   | -0.504354   |  0.0516412   |  0.10941    | -0.439604    |  0.40147    | -0.624213   | -1.89856    |  0.563193   | -0.164388    |\n 3275 | Venezuela                      | 2000 |  0.153418   |  0.0504507   | -0.500962   |  0.0671066   |  0.12278    | -0.492572    |  0.773923   | -0.71243    |  0.188459   |  0.785974   | -0.267634    |\n 3276 | Venezuela                      | 2001 |  0.126592   |  0.0616729   | -0.498135   |  0.082572    |  0.136151   | -0.545539    |  0.784269   | -0.722896   |  0.129313   |  0.8416     | -0.261762    |\n 3277 | Venezuela                      | 2002 |  0.0997656  |  0.0757007   | -0.495308   |  0.0408155   |  0.049244   | -0.603803    |  0.773923   | -0.733362   | -2.50692    |  0.873846   | -0.23494     |\n 3278 | Venezuela                      | 2003 |  0.0639972  |  0.0897286   | -0.492481   |  0.00833814  | -0.0169387  | -0.65677     |  0.763577   | -0.740838   | -2.25766    |  0.875936   | -0.256117    |\n 3279 | Venezuela                      | 2004 |  0.0371709  |  0.100951    | -0.489654   |  0.0794789   |  0.0893548  | -0.709737    |  0.835998   | -0.74981    |  3.33166    |  0.929415   | -0.332374    |\n 3280 | Venezuela                      | 2005 |  0.00140259 |  0.114979    | -0.486262   |  0.127422    |  0.149521   | -0.757408    |  0.85669    | -0.760276   |  1.4939     |  1.04221    | -0.276301    |\n 3281 | Venezuela                      | 2006 | -0.0343658  |  0.126201    | -0.483435   |  0.176911    |  0.216372   | -0.799781    |  0.846344   | -0.769247   |  1.51503    |  1.11481    | -0.250276    |\n 3282 | Venezuela                      | 2007 | -0.061192   |  0.140229    | -0.480608   |  0.2264      |  0.276538   | -0.836859    |  0.846344   | -0.775228   |  1.19817    |  1.18736    | -0.214962    |\n 3283 | Venezuela                      | 2008 | -0.0969604  |  0.151451    | -0.477781   |  0.257331    |  0.316649   | -0.873936    |  0.835998   | -0.779714   |  0.460954   |  1.25116    | -0.183677    |\n 3284 | Venezuela                      | 2009 | -0.132729   |  0.165479    | -0.474954   |  0.237226    |  0.269853   | -0.905716    |  0.846344   | -0.781209   | -1.33244    |  1.28922    | -0.160452    |\n 3285 | Venezuela                      | 2010 | -0.168497   |  0.176701    | -0.472127   |  0.227947    |  0.236427   | -0.9322      |  0.887728   | -0.781209   | -0.97123    |  1.31554    | -0.176631    |\n 3286 | Zambia                         | 1980 |  1.51262    | -0.471665    | -0.613361   | -0.368151    | -0.580495   |  1.6473      | -0.933153   |  1.29562    |  0.167335   | -2.79572    |  0.179422    |\n 3287 | Zambia                         | 1981 |  1.52156    | -0.466054    | -0.611778   | -0.367424    | -0.577821   |  1.6473      | -0.943499   |  1.31057    | -0.83456    | -2.79411    |  0.208615    |\n 3288 | Zambia                         | 1982 |  1.51262    | -0.459882    | -0.610194   | -0.36778     | -0.583169   |  1.6473      | -0.964191   |  1.32552    | -0.136845   | -2.81689    |  0.20565     |\n 3289 | Zambia                         | 1983 |  1.47685    | -0.45399     | -0.608555   | -0.368012    | -0.587848   |  1.6473      | -0.984883   |  1.37038    | -0.0396765  | -2.83326    |  0.216487    |\n 3290 | Zambia                         | 1984 |  1.39637    | -0.447818    | -0.606915   | -0.368059    | -0.590522   |  1.59434     | -1.02627    |  1.41523    | -0.784286   | -2.80452    |  0.234965    |\n 3291 | Zambia                         | 1985 |  1.28906    | -0.441646    | -0.605219   | -0.367858    | -0.591859   |  1.54137     | -1.08834    |  1.47504    | -0.665233   | -2.79221    |  0.24041     |\n 3292 | Zambia                         | 1986 |  1.1907     | -0.435754    | -0.603579   | -0.36778     | -0.593196   |  1.54137     | -1.16076    |  1.53485    | -0.100935   | -2.81841    |  0.245097    |\n 3293 | Zambia                         | 1987 |  1.10128    | -0.429582    | -0.60194    | -0.367455    | -0.593865   |  1.54137     | -1.22284    |  1.59466    | -0.0798114  | -2.83565    |  0.259791    |\n 3294 | Zambia                         | 1988 |  1.0208     | -0.42369     | -0.60047    | -0.366667    | -0.591191   |  1.54137     | -1.25388    |  1.63951    | -0.248801   | -2.83237    |  0.271284    |\n 3295 | Zambia                         | 1989 |  0.940322   | -0.417798    | -0.598774   | -0.366806    | -0.593865   |  1.54137     | -1.37803    |  1.66942    | -0.458981   | -2.86544    |  0.293504    |\n 3296 | Zambia                         | 1990 |  0.868785   | -0.411626    | -0.597078   | -0.366868    | -0.596539   |  1.4884      | -1.50218    |  1.68437    | -0.502496   | -2.87376    |  0.30591     |\n 3297 | Zambia                         | 1991 |  0.797249   | -0.405734    | -0.595381   | -0.366868    | -0.597876   |  1.54137     | -1.65737    |  1.69932    | -1.07474    | -2.93626    |  0.342226    |\n 3298 | Zambia                         | 1992 |  0.743596   | -0.399843    | -0.593685   | -0.3671      | -0.600884   |  1.54137     | -1.79186    |  1.69932    | -1.02615    | -2.97543    |  0.358236    |\n 3299 | Zambia                         | 1993 |  0.725712   | -0.39367     | -0.591989   | -0.366234    | -0.597876   |  1.4884      | -1.88498    |  1.68437    |  0.775697   | -3.00172    |  0.333464    |\n 3300 | Zambia                         | 1994 |  0.770422   | -0.387218    | -0.590293   | -0.367409    | -0.605631   |  1.46192     | -1.99878    |  1.65447    | -2.47735    | -3.00152    |  0.411382    |\n 3301 | Zambia                         | 1995 |  0.850901   | -0.380484    | -0.588597   | -0.367053    | -0.605497   |  1.43014     | -2.10224    |  1.60961    | -1.1888     | -3.06191    |  0.406657    |\n 3302 | Zambia                         | 1996 |  0.949264   | -0.37347     | -0.586901   | -0.366249    | -0.603491   |  1.41955     | -2.18501    |  1.56475    |  0.731337   | -3.1378     |  0.392193    |\n 3303 | Zambia                         | 1997 |  1.0208     | -0.365615    | -0.584639   | -0.365739    | -0.602957   |  1.40366     | -2.24708    |  1.53485    |  0.0363687  | -3.16198    |  0.422252    |\n 3304 | Zambia                         | 1998 |  1.04763    | -0.357759    | -0.582378   | -0.365785    | -0.605029   |  1.38777     | -2.29881    |  1.50495    | -1.05361    | -3.15963    |  0.45155     |\n 3305 | Zambia                         | 1999 |  1.02974    | -0.350745    | -0.580116   | -0.365136    | -0.603959   |  1.36658     | -2.32985    |  1.44514    | -0.191767   | -3.14133    |  0.428393    |\n 3306 | Zambia                         | 2000 |  0.97609    | -0.342329    | -0.577854   | -0.364563    | -0.603358   |  1.3348      | -2.35054    |  1.37038    |  0.0891779  | -3.08514    |  0.406101    |\n 3307 | Zambia                         | 2001 |  0.913496   | -0.333912    | -0.575593   | -0.363759    | -0.60182    |  1.35598     | -2.37124    |  1.23581    |  0.372235   | -3.02368    |  0.374239    |\n 3308 | Zambia                         | 2002 |  0.877727   | -0.325495    | -0.573331   | -0.362986    | -0.600684   |  1.36658     | -2.31951    |  1.07134    |  0.0363687  | -2.91473    |  0.339095    |\n 3309 | Zambia                         | 2003 |  0.859843   | -0.317078    | -0.57107    | -0.361903    | -0.597876   |  1.37187     | -2.29881    |  0.906868   |  0.249718   | -2.83105    |  0.300601    |\n 3310 | Zambia                         | 2004 |  0.859843   | -0.308662    | -0.568808   | -0.360666    | -0.595202   |  1.37187     | -2.22639    |  0.757348   |  0.64473    | -2.73805    |  0.256561    |\n 3311 | Zambia                         | 2005 |  0.868785   | -0.297439    | -0.566547   | -0.35912     | -0.591859   |  1.38247     | -2.15397    |  0.607829   |  0.441943   | -2.6444     |  0.227981    |\n 3312 | Zambia                         | 2006 |  0.886669   | -0.289023    | -0.56372    | -0.357573    | -0.588517   |  1.38777     | -2.08155    |  0.503165   |  0.648955   | -2.57693    |  0.200567    |\n 3313 | Zambia                         | 2007 |  0.904554   | -0.280606    | -0.561458   | -0.355717    | -0.583837   |  1.39306     | -1.96774    |  0.428405   |  0.672191   | -2.50091    |  0.177191    |\n 3314 | Zambia                         | 2008 |  0.93138    | -0.269384    | -0.558631   | -0.353861    | -0.579826   |  1.39836     | -1.80221    |  0.361121   |  0.60882    | -2.40735    |  0.152857    |\n 3315 | Zambia                         | 2009 |  0.985032   | -0.258162    | -0.555804   | -0.351387    | -0.574478   |  1.39836     | -1.66771    |  0.27739    |  0.627831   | -2.32909    |  0.13148     |\n 3316 | Zambia                         | 2010 |  1.03869    | -0.246939    | -0.552977   | -0.348448    | -0.568461   |  1.38777     | -1.53322    |  0.205621   |  0.84118    | -2.25344    |  0.108478    |\n 3317 | Zimbabwe                       | 1980 |  1.53944    | -0.436034    | -0.553543   | -0.366821    | -0.58718    |  1.91214     | -0.664159   |  0.503165   |  1.5784     | -2.47676    | -0.00172798  |\n 3318 | Zimbabwe                       | 1981 |  1.74511    | -0.428459    | -0.549585   | -0.365197    | -0.581163   |  1.85917     | -0.571046   |  0.446347   |  1.97975    | -2.46938    | -0.0050171   |\n 3319 | Zimbabwe                       | 1982 |  1.87924    | -0.420323    | -0.545062   | -0.364811    | -0.581832   |  1.85917     | -0.519317   |  0.374578   | -0.10516    | -2.43794    |  0.0348938   |\n 3320 | Zimbabwe                       | 1983 |  1.94184    | -0.411626    | -0.540539   | -0.364563    | -0.583837   |  1.80621     | -0.477933   |  0.293837   | -0.326958   | -2.38139    |  0.025724    |\n 3321 | Zimbabwe                       | 1984 |  1.89713    | -0.402929    | -0.536016   | -0.364857    | -0.588517   |  1.75324     | -0.426203   |  0.220573   | -1.06417    | -2.27526    |  0.011       |\n 3322 | Zimbabwe                       | 1985 |  1.79876    | -0.393951    | -0.531493   | -0.363759    | -0.585843   |  1.70027     | -0.38482    |  0.157774   |  0.80527    | -2.19027    | -0.0541725   |\n 3323 | Zimbabwe                       | 1986 |  1.68252    | -0.384973    | -0.52697    | -0.36345     | -0.58718    |  1.6473      | -0.343436   |  0.109928   | -0.210778   | -2.06614    | -0.0660095   |\n 3324 | Zimbabwe                       | 1987 |  1.56627    | -0.376276    | -0.522447   | -0.363295    | -0.589185   |  1.59434     | -0.33309    |  0.0785291  | -0.42624    | -1.9742     | -0.0845613   |\n 3325 | Zimbabwe                       | 1988 |  1.40531    | -0.367579    | -0.517924   | -0.362058    | -0.585843   |  1.4884      | -0.374474   |  0.0650723  |  0.934125   | -1.89073    | -0.130946    |\n 3326 | Zimbabwe                       | 1989 |  1.19964    | -0.359162    | -0.513401   | -0.36113     | -0.584506   |  1.39836     | -0.426203   |  0.0680627  |  0.441943   | -1.78358    | -0.143274    |\n 3327 | Zimbabwe                       | 1990 |  0.958206   | -0.350745    | -0.509443   | -0.359738    | -0.581163   |  1.29772     | -0.529663   |  0.0875002  |  0.81372    | -1.69867    | -0.165893    |\n 3328 | Zimbabwe                       | 1991 |  0.71677    | -0.345134    | -0.505485   | -0.358656    | -0.578489   |  1.26064     | -0.602084   |  0.120395   |  0.524325   | -1.62624    | -0.174354    |\n 3329 | Zimbabwe                       | 1992 |  0.493218   | -0.336717    | -0.502093   | -0.360666    | -0.588517   |  1.21827     | -0.767619   |  0.16226    | -2.54917    | -1.5699     | -0.113576    |\n 3330 | Zimbabwe                       | 1993 |  0.305434   | -0.331106    | -0.4987     | -0.360357    | -0.589185   |  1.1653      | -0.953845   |  0.210106   | -0.422015   | -1.60314    | -0.140672    |\n 3331 | Zimbabwe                       | 1994 |  0.180244   | -0.325495    | -0.495874   | -0.358656    | -0.583837   |  1.09645     | -1.14007    |  0.260943   |  1.30379    | -1.64693    | -0.151898    |\n 3332 | Zimbabwe                       | 1995 |  0.0818814  | -0.319884    | -0.492481   | -0.358501    | -0.585174   |  1.0064      | -1.35734    |  0.310284   | -0.621211   | -1.6566     | -0.090972    |\n 3333 | Zimbabwe                       | 1996 |  0.0103447  | -0.314273    | -0.489654   | -0.356336    | -0.577821   |  0.969324    | -1.51252    |  0.350655   |  1.51503    | -1.72263    | -0.106006    |\n 3334 | Zimbabwe                       | 1997 | -0.061192   | -0.308662    | -0.486827   | -0.355717    | -0.577152   |  0.91106     | -1.65737    |  0.379063   | -0.103047   | -1.71993    | -0.0591903   |\n 3335 | Zimbabwe                       | 1998 | -0.150613   | -0.303051    | -0.484566   | -0.355099    | -0.575815   |  0.842203    | -1.83325    |  0.397006   | -0.0671372  | -1.73751    | -0.0439544   |\n 3336 | Zimbabwe                       | 1999 | -0.257918   | -0.297439    | -0.481739   | -0.355253    | -0.577821   |  0.762752    | -1.96774    |  0.404482   | -0.853994   | -1.71036    | -0.0258828   |\n 3337 | Zimbabwe                       | 2000 | -0.374165   | -0.294634    | -0.479477   | -0.356026    | -0.581832   |  0.688598    | -2.08155    |  0.410463   | -1.33033    | -1.67801    | -0.0201173   |\n 3338 | Zimbabwe                       | 2001 | -0.490412   | -0.289023    | -0.477216   | -0.355717    | -0.581832   |  0.651521    | -2.13328    |  0.414948   | -0.386105   | -1.65219    | -0.0437481   |\n 3339 | Zimbabwe                       | 2002 | -0.570891   | -0.286217    | -0.47552    | -0.357882    | -0.589854   |  0.61974     | -2.19535    |  0.423919   | -2.5724     | -1.60978    | -0.0054933   |\n 3340 | Zimbabwe                       | 2003 | -0.588775   | -0.283412    | -0.473258   | -0.361594    | -0.603491   |  0.593257    | -2.22639    |  0.431395   | -4.29398    | -1.58891    |  0.027761    |\n 3341 | Zimbabwe                       | 2004 | -0.526181   | -0.277801    | -0.471562   | -0.362677    | -0.60777    |  0.57207     | -2.24708    |  0.443357   | -1.94292    | -1.65174    |  0.000939231 |\n 3342 | Zimbabwe                       | 2005 | -0.409934   | -0.274995    | -0.4693     | -0.363605    | -0.611781   |  0.550883    | -2.22639    |  0.453823   | -1.93658    | -1.68416    |  0.0160886   |\n 3343 | Zimbabwe                       | 2006 | -0.275802   | -0.269384    | -0.466474   | -0.364223    | -0.614455   |  0.519103    | -2.18501    |  0.458309   | -1.48031    | -1.71235    |  0.022425    |\n 3344 | Zimbabwe                       | 2007 | -0.150613   | -0.263773    | -0.463081   | -0.364733    | -0.617062   |  0.497916    | -2.11259    |  0.458309   | -1.53523    | -1.71896    |  0.0324028   |\n 3345 | Zimbabwe                       | 2008 | -0.0164816  | -0.255356    | -0.460254   | -0.367409    | -0.626421   |  0.482026    | -2.08155    |  0.428405   | -4.4841     | -1.69957    |  0.0975182   |\n 3346 | Zimbabwe                       | 2009 |  0.108708   | -0.249745    | -0.456297   | -0.365909    | -0.622477   |  0.476729    | -1.99878    |  0.382054   |  0.460954   | -1.75564    |  0.00659415  |\n 3347 | Zimbabwe                       | 2010 |  0.233897   | -0.241328    | -0.452339   | -0.364223    | -0.617931   |  0.482026    | -1.78152    |  0.307294   |  1.21718    | -1.68608    | -0.0305482   |\n+------+--------------------------------+------+-------------+--------------+-------------+--------------+-------------+--------------+-------------+-------------+-------------+-------------+--------------+\n</div>"]}}],"execution_count":28},{"cell_type":"code","source":["time_fin = dt.datetime.now()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":29},{"cell_type":"code","source":["time_ini"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[29]: datetime.datetime(2019, 12, 5, 3, 59, 55, 822558)</div>"]}}],"execution_count":30},{"cell_type":"code","source":["time_fin"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[30]: datetime.datetime(2019, 12, 5, 4, 1, 38, 885990)</div>"]}}],"execution_count":31},{"cell_type":"code","source":["time_ini-time_fin"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[31]: datetime.timedelta(days=-1, seconds=86296, microseconds=936568)</div>"]}}],"execution_count":32},{"cell_type":"code","source":["83773/3600"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[32]: 23.27027777777778</div>"]}}],"execution_count":33}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.5","nbconvert_exporter":"python","file_extension":".py"},"name":"Ejemp_pyspark_v3 blob","notebookId":1990005137418951},"nbformat":4,"nbformat_minor":0}
